{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenFIBSEM DB\n",
    "\n",
    "sqlite3 database for storing metadata about FIBSEM datasets.\n",
    "\n",
    "https://www.sqlitetutorial.net/sqlite-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATABASE\n",
    "\n",
    "--- EXPERIMENT MANAGMENT ---\n",
    "\n",
    "project\n",
    "- id\n",
    "- name\n",
    "- user_id\n",
    "\n",
    "user:\n",
    "- id\n",
    "- name\n",
    "\n",
    "experiment\n",
    "- id\n",
    "- name\n",
    "- project_id\n",
    "- user_id\n",
    "- sample_id\n",
    "- path\n",
    "\n",
    "sample\n",
    "- id\n",
    "- name\n",
    "\n",
    "\n",
    "\n",
    "---- Analytics ----\n",
    "\n",
    "ml\n",
    "detection\n",
    "alignment\n",
    "interaction\n",
    "history\n",
    "steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MILESTONE 1\n",
    "# TODO: initialise database script\n",
    "# TODO: migrate ml data collection to store in db\n",
    "# TODO: setup projects, experiment, user tables\n",
    "# TODO: separate ETL from statistics / analytics application\n",
    "# TODO: enable user to select project, experiment\n",
    "# TODO: enable multi-experiment analytics\n",
    "# TODO: fix experiment to dataframe function, make actually useful\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import datetime\n",
    "import sqlite3\n",
    "from fibsem.db.util import *\n",
    "from fibsem.db.util import _create_database\n",
    "from fibsem import config as cfg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE DATABASE / TABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_create_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "database = cfg.DATABASE_PATH\n",
    "conn = create_connection(database)\n",
    "# create_project(conn, \n",
    "#     (\"WAFFLE-METHOD-DEVELOPMENT\", datetime.datetime.now(), \"patrick\")\n",
    "# )\n",
    "\n",
    "create_project(conn, \n",
    "    (\"AUTOLIFTOUT-METHOD-DEVELOPMENT\", datetime.datetime.now(), \"patrick\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_user(conn, \n",
    "    ('hannah', 'hannah.siems@monash.edu', 'password')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE SAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_sample(\n",
    "    conn, \n",
    "    (\"WAFFLE-01\", 1, datetime.datetime.now(), \"hannah\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE EXPERIMENT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_experiment(\n",
    "    conn, \n",
    "    (\"WAFFLE-01\", 1, datetime.datetime.now(), \"hannah\", 1, \"autolamella\", \"waffle\", \"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "print(\"PROJECTS\")\n",
    "df = pd. read_sql('SELECT * from projects', conn)\n",
    "display(df)\n",
    "\n",
    "print(\"USERS\")\n",
    "df = pd. read_sql('SELECT * from users', conn)\n",
    "display(df)\n",
    "\n",
    "print(\"SAMPLES\")\n",
    "df = pd. read_sql('SELECT * from samples', conn)\n",
    "display(df)\n",
    "\n",
    "print(\"EXPERIMENTS\")\n",
    "df = pd. read_sql('SELECT * from experiments', conn)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### REPLACE ? --> UPSERT?\n",
    "\n",
    "# might not want to use, replaces experiment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sync Experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PROJECT_NAME = \"WAFFLE-METHOD-DEVELOPMENT\"\n",
    "\n",
    "df = pd.read_sql(f\"SELECT * FROM projects WHERE name='{PROJECT_NAME}'\", conn)\n",
    "PROJECT_IDS = df[\"id\"].values\n",
    "print(PROJECT_IDS)\n",
    "df = pd.read_sql(f\"SELECT * FROM experiments WHERE project_id={PROJECT_IDS[0]}\", conn)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload all data to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from autolamella import config as cfg\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from autolamella.tools.data import calculate_statistics_dataframe\n",
    "\n",
    "\n",
    "import datetime\n",
    "import sqlite3\n",
    "from fibsem.db.util import *\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _update_experiment(conn, PATH:str, _UPDATE: bool, program: str = \"autolamella\", method: str = \"waffle\", user: str = \"hannah\", project_id: int = 1, sample_id: int = 1):\n",
    "    \n",
    "    \"\"\"\"\"\"\n",
    "    print(PATH)   \n",
    "    print(\"-------EXPERIMENT-------\")\n",
    "\n",
    "    if program == \"autolamella\":\n",
    "        from autolamella.structures import Experiment\n",
    "    if program == \"autoliftout\":\n",
    "        from liftout.structures import Experiment\n",
    "    exp = Experiment.load(os.path.join(PATH, \"experiment.yaml\"))\n",
    "    df = exp.to_dataframe_v2()\n",
    "\n",
    "    # format date as datetime\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], unit=\"s\")\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], utc=True)\n",
    "\n",
    "    # drop experiment_id\n",
    "    df = df.drop(columns=[\"experiment_id\", \"num_lamella\"])\n",
    "    df[\"project_id\"] = project_id\n",
    "    df[\"sample_id\"] = sample_id\n",
    "    df[\"user\"] = user\n",
    "    df[\"method\"] = method\n",
    "    \n",
    "    display(df)\n",
    "\n",
    "    ret  = input(\"continue?\")\n",
    "    \n",
    "    if \"n\" in ret.lower():\n",
    "        return\n",
    "\n",
    "    if _UPDATE:\n",
    "        df.to_sql('experiments', conn, if_exists='append', index = False)\n",
    "\n",
    "    print(\"------------------\")\n",
    "\n",
    "    print(\"-----------DATABASE EXPERIMENTS -------\")\n",
    "    df_exp = pd.read_sql(\"SELECT * FROM experiments\", conn)\n",
    "    display(df_exp)\n",
    "    print(\"------------------\")\n",
    "\n",
    "    # return\n",
    "\n",
    "    # break\n",
    "\n",
    "    dfs = calculate_statistics_dataframe(PATH, program=program)\n",
    "\n",
    "    print(\"-------HISTORY----------\")\n",
    "    df = dfs[1]\n",
    "\n",
    "    # format date as datetime\n",
    "    df[\"start\"] = pd.to_datetime(df[\"start\"], unit=\"s\")\n",
    "    df[\"start\"] = pd.to_datetime(df[\"start\"], utc=True)\n",
    "\n",
    "    df[\"end\"] = pd.to_datetime(df[\"start\"], unit=\"s\")\n",
    "    df[\"end\"] = pd.to_datetime(df[\"start\"], utc=True)\n",
    "\n",
    "\n",
    "    EXP_ID = df_exp[df_exp[\"name\"]==df[\"exp_name\"].iloc[0]][\"id\"].iloc[0]\n",
    "\n",
    "    df[\"experiment_id\"] = EXP_ID\n",
    "    # drop experiment_id\n",
    "    df = df.drop(columns=[\"exp_id\", \"exp_name\"])\n",
    "    \n",
    "    display(df.head())\n",
    "\n",
    "    if _UPDATE:\n",
    "        df.to_sql('history', conn, if_exists='append', index = False)\n",
    "\n",
    "    print(\"------------------\")\n",
    "\n",
    "\n",
    "    print(\"-------STEPS----------\")\n",
    "\n",
    "    df = dfs[3]\n",
    "    # display(df)\n",
    "    # # format date as datetime\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], unit=\"s\")\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True)\n",
    "\n",
    "    EXP_ID = df_exp[df_exp[\"name\"]==df[\"exp_name\"].iloc[0]][\"id\"].iloc[0]\n",
    "\n",
    "    df[\"experiment_id\"] = EXP_ID\n",
    "    # drop experiment_id\n",
    "    df = df.drop(columns=[\"exp_id\", \"exp_name\"])\n",
    "\n",
    "    # rename lamella to petname\n",
    "    df = df.rename(columns={\"lamella\": \"petname\"})\n",
    "\n",
    "    # replace NA with 0\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    display(df.head())\n",
    "    \n",
    "    if _UPDATE:\n",
    "        df.to_sql('steps', conn, if_exists='append', index = False)\n",
    "\n",
    "    print(\"------------------\")\n",
    "\n",
    "\n",
    "    print(\"-------DETECTIONS----------\")\n",
    "    df = dfs[5]\n",
    "\n",
    "\n",
    "    # # # format date as datetime\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], unit=\"s\")\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True)\n",
    "\n",
    "    EXP_ID = df_exp[df_exp[\"name\"]==df[\"exp_name\"].iloc[0]][\"id\"].iloc[0]\n",
    "\n",
    "    df[\"experiment_id\"] = EXP_ID\n",
    "    # # drop experiment_id\n",
    "    df = df.drop(columns=[\"exp_id\", \"exp_name\"])\n",
    "\n",
    "    # # rename lamella to petname\n",
    "    df = df.rename(columns={\"lamella\": \"petname\"})\n",
    "\n",
    "    # # replace NA with 0\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    display(df.head())\n",
    "    \n",
    "    if _UPDATE:\n",
    "        df.to_sql('detections', conn, if_exists='append', index = False)\n",
    "\n",
    "    print(\"------------------\")\n",
    "\n",
    "\n",
    "    #### INTERACTIONS\n",
    "    print(\"-------INTERACTIONS----------\")\n",
    "    df = dfs[6]\n",
    "\n",
    "    # # # format date as datetime\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], unit=\"s\")\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True)\n",
    "\n",
    "    EXP_ID = df_exp[df_exp[\"name\"]==df[\"exp_name\"].iloc[0]][\"id\"].iloc[0]\n",
    "\n",
    "\n",
    "    df[\"experiment_id\"] = EXP_ID\n",
    "    # # drop experiment_id\n",
    "    df = df.drop(columns=[\"exp_id\", \"exp_name\"])\n",
    "\n",
    "    # # rename lamella to petname\n",
    "    df = df.rename(columns={\"lamella\": \"petname\"})\n",
    "\n",
    "    # # replace NA with 0\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    display(df.head())\n",
    "    \n",
    "    if _UPDATE:\n",
    "        df.to_sql('interactions', conn, if_exists='append', index = False)\n",
    "\n",
    "    print(\"------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create / connect to db\n",
    "database = \"fibsem.db\"\n",
    "conn = create_connection(database)\n",
    "\n",
    "\n",
    "_UPDATE = True\n",
    "\n",
    "EXPERIMENTS = [\n",
    "    \"/home/patrick/github/data/EXPERIMENTS/HANNAH-WAFFLE-01-07092023\",\n",
    "    \"/home/patrick/github/data/EXPERIMENTS/HANNAH-WAFFLE-01-12092023\",\n",
    "    \"/home/patrick/github/data/EXPERIMENTS/HANNAH-WAFFLE-02-13092023\",\n",
    "    \"/home/patrick/github/data/EXPERIMENTS/HANNAH-WAFFLE-01-20092023\",\n",
    "    \"/home/patrick/github/data/EXPERIMENTS/HANNAH-WAAFFLE-01-21092023\",\n",
    "    ]\n",
    "# AUTOLIFTOUT_EXPERIMENTS = [\"/home/patrick/github/data/EXPERIMENTS/AUTOLIFTOUT-WAFFLE-01-24082023\"]\n",
    "\n",
    "for PATH in EXPERIMENTS:\n",
    "    _update_experiment(conn, PATH, _UPDATE, program=\"autolamella\", method=\"waffle\", user=\"hannah\")\n",
    "    \n",
    "# for PATH in AUTOLIFTOUT_EXPERIMENTS:\n",
    "#     _update_experiment(conn, PATH, _UPDATE, program=\"autoliftout\", method=\"autoliftout\", user=\"patrick\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fibsem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
