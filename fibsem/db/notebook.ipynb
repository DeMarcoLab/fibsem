{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenFIBSEM DB\n",
    "\n",
    "sqlite3 database for storing metadata about FIBSEM datasets.\n",
    "\n",
    "https://www.sqlitetutorial.net/sqlite-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import sqlite3\n",
    "from fibsem.db.util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create TABLE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a database connection\n",
    "conn = create_connection(database)\n",
    "\n",
    "# create tables\n",
    "if conn is not None:\n",
    "    # create projects table\n",
    "    create_table(conn, sql_create_projects_table)\n",
    "\n",
    "    # create tasks table\n",
    "    create_table(conn, sql_create_tasks_table)\n",
    "else:\n",
    "    print(\"Error! cannot create the database connection.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### INSERT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# create a database connection\n",
    "conn = create_connection(database)\n",
    "with conn:\n",
    "    # create a new project\n",
    "    project = ('Cool App with SQLite & Python', '2015-01-01', '2015-01-30');\n",
    "    project_id = create_project(conn, project)\n",
    "\n",
    "    # tasks\n",
    "    task_1 = ('Analyze the requirements of the app', 1, 1, project_id, '2015-01-01', '2015-01-02')\n",
    "    task_2 = ('Confirm with user about the top requirements', 1, 1, project_id, '2015-01-03', '2015-01-05')\n",
    "\n",
    "    # create tasks\n",
    "    create_task(conn, task_1)\n",
    "    create_task(conn, task_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create a database connection\n",
    "conn = create_connection(database)\n",
    "with conn:\n",
    "    update_task(conn, (2, '2015-01-04', '2015-01-06', 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete Task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = create_connection(database)\n",
    "with conn:\n",
    "    delete_task(conn, 1);\n",
    "    # delete_all_tasks(conn);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a database connection\n",
    "conn = create_connection(database)\n",
    "with conn:\n",
    "    print(\"1. Query task by priority:\")\n",
    "    select_task_by_priority(conn, 1)\n",
    "\n",
    "    print(\"2. Query all tasks\")\n",
    "    select_all_tasks(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PANDAS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "conn = create_connection(database)\n",
    "df = pd. read_sql('SELECT * from tasks', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the data to a sqlite table\n",
    "\n",
    "df = pd.DataFrame({\"id\": 5, \"name\": \"test\", \"priority\": 3, \"status_id\": 3, \"project_id\": 3, \"begin_date\": '2016-01-12', \"end_date\": '2016-02-24'}, \n",
    "index=[0])\n",
    "\n",
    "display(df)\n",
    "df.to_sql('tasks', conn, if_exists='append', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd. read_sql('SELECT * from tasks', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATABASE\n",
    "\n",
    "--- EXPERIMENT MANAGMENT ---\n",
    "\n",
    "project\n",
    "- id\n",
    "- name\n",
    "- user_id\n",
    "\n",
    "user:\n",
    "- id\n",
    "- name\n",
    "\n",
    "experiment\n",
    "- id\n",
    "- name\n",
    "- project_id\n",
    "- user_id\n",
    "- sample_id\n",
    "- path\n",
    "\n",
    "sample\n",
    "- id\n",
    "- name\n",
    "\n",
    "\n",
    "\n",
    "---- Analytics ----\n",
    "\n",
    "ml\n",
    "detection\n",
    "alignment\n",
    "interaction\n",
    "history\n",
    "steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MILESTONE 1\n",
    "# TODO: initialise database script\n",
    "# TODO: migrate ml data collection to store in db\n",
    "# TODO: setup projects, experiment, user tables\n",
    "# TODO: separate ETL from statistics / analytics application\n",
    "# TODO: enable user to select project, experiment\n",
    "# TODO: enable multi-experiment analytics\n",
    "# TODO: fix experiment to dataframe function, make actually useful\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import datetime\n",
    "import sqlite3\n",
    "from fibsem.db.util import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_CREATE_PROJECTS_TABLE = \"\"\" CREATE TABLE IF NOT EXISTS projects (\n",
    "                                    id INTEGER PRIMARY KEY,\n",
    "                                    name VARCHAR(100) NOT NULL,\n",
    "                                    date TIMESTAMP NOT NULL,\n",
    "                                    user VARCHAR(100) NOT NULL\n",
    "                                ); \"\"\"\n",
    "\n",
    "SQL_CREATE_USERS_TABLES = \"\"\"CREATE TABLE IF NOT EXISTS users (\n",
    "                                id INTEGER PRIMARY KEY,\n",
    "                                name VARCHAR(100) NOT NULL,\n",
    "                                email VARCHAR(100) NOT NULL,\n",
    "                                password VARCHAR(100) NOT NULL\n",
    "                            );\"\"\"\n",
    "\n",
    "\n",
    "SQL_CREATE_SAMPLES_TABLE = \"\"\"CREATE TABLE IF NOT EXISTS samples (\n",
    "                                id INTEGER PRIMARY KEY,\n",
    "                                name VARCHAR(100) NOT NULL,\n",
    "                                project_id INTEGER NOT NULL,\n",
    "                                date TIMESTAMP NOT NULL,\n",
    "                                user VARCHAR(100) NOT NULL,\n",
    "                                FOREIGN KEY (project_id) REFERENCES projects (id)\n",
    "                                );\"\"\"\n",
    "\n",
    "\n",
    "SQL_CREATE_EXPERIMENTS_TABLE = \"\"\"CREATE TABLE IF NOT EXISTS experiments (\n",
    "                                id INTEGER PRIMARY KEY,\n",
    "                                name VARCHAR(100) NOT NULL,\n",
    "                                project_id INTEGER NOT NULL,\n",
    "                                date TIMESTAMP NOT NULL,\n",
    "                                user VARCHAR(100) NOT NULL,\n",
    "                                sample_id INTEGER NOT NULL,\n",
    "                                program VARCHAR(100) NOT NULL,\n",
    "                                method VARCHAR(100) NOT NULL,\n",
    "                                path VARCHAR(100) NOT NULL,\n",
    "                                FOREIGN KEY (project_id) REFERENCES projects (id)\n",
    "                                FOREIGN KEY (sample_id) REFERENCES samples (id)\n",
    "                            );\"\"\"\n",
    "\n",
    "\n",
    "# create / connect to db\n",
    "database = \"fibsem.db\"\n",
    "conn = create_connection(database)\n",
    "\n",
    "# create tables\n",
    "create_table(conn, SQL_CREATE_PROJECTS_TABLE)\n",
    "create_table(conn, SQL_CREATE_USERS_TABLES)\n",
    "create_table(conn, SQL_CREATE_SAMPLES_TABLE)\n",
    "create_table(conn, SQL_CREATE_EXPERIMENTS_TABLE)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# create_project(conn, \n",
    "#     (\"WAFFLE-METHOD-DEVELOPMENT\", datetime.datetime.now(), \"patrick\")\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_user(conn, \n",
    "    ('hannah', 'hannah.siems@monash.edu', 'password')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE SAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_sample(\n",
    "    conn, \n",
    "    (\"WAFFLE-01\", 1, datetime.datetime.now(), \"hannah\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE EXPERIMENT\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_experiment(conn,\n",
    "\n",
    "    (\"WAFFLE-15082023\", 1, datetime.datetime.now(), \"hannah\", 1)\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "print(\"PROJECTS\")\n",
    "df = pd. read_sql('SELECT * from projects', conn)\n",
    "display(df)\n",
    "\n",
    "print(\"USERS\")\n",
    "df = pd. read_sql('SELECT * from users', conn)\n",
    "display(df)\n",
    "\n",
    "print(\"SAMPLES\")\n",
    "df = pd. read_sql('SELECT * from samples', conn)\n",
    "display(df)\n",
    "\n",
    "print(\"EXPERIMENTS\")\n",
    "df = pd. read_sql('SELECT * from experiments', conn)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### REPLACE ? --> UPSERT?\n",
    "\n",
    "# might not want to use, replaces experiment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sync Experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from autolamella import config as cfg\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from autolamella.structures import Experiment\n",
    "from autolamella.tools.data import calculate_statistics_dataframe\n",
    "\n",
    "EXPERIMENTS = [\n",
    "\"/home/patrick/github/autolamella/autolamella/log/HANNAH-WAFFLE-01-09082023\",\n",
    "\"/home/patrick/github/autolamella/autolamella/log/HANNAH-WAFFLE-02-09082023\",\n",
    "\"/home/patrick/github/autolamella/autolamella/log/HANNAH-WAFFLE-01-15082023\",\n",
    "]\n",
    "\n",
    "for PATH in EXPERIMENTS:\n",
    "    \n",
    "    print(PATH)   \n",
    "\n",
    "    exp = Experiment.load(os.path.join(PATH, \"experiment.yaml\"))\n",
    "    df = exp.to_dataframe_v2()\n",
    "\n",
    "    # format date as datetime\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], unit=\"s\")\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], utc=True)\n",
    "\n",
    "    # drop experiment_id\n",
    "    df = df.drop(columns=[\"experiment_id\", \"num_lamella\"])\n",
    "    df[\"project_id\"] = 1\n",
    "    df[\"sample_id\"] = 1\n",
    "    df[\"user\"] = \"hannah\"\n",
    "    df[\"method\"] = \"waffle\"\n",
    "    \n",
    "    display(df)\n",
    "\n",
    "    df.to_sql('experiments', conn, if_exists='append', index = False)\n",
    "\n",
    "    print(\"------------------\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(\"SELECT * FROM [experiments]\", conn)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PROJECT_NAME = \"WAFFLE-METHOD-DEVELOPMENT\"\n",
    "\n",
    "df = pd.read_sql(f\"SELECT * FROM projects WHERE name='{PROJECT_NAME}'\", conn)\n",
    "PROJECT_IDS = df[\"id\"].values\n",
    "\n",
    "df = pd.read_sql(f\"SELECT * FROM experiments WHERE project_id={PROJECT_IDS[0]}\", conn)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SQL_CREATE_HISTORY_TABLE = \"\"\"CREATE TABLE IF NOT EXISTS history (\n",
    "                                id INTEGER PRIMARY KEY,\n",
    "                                petname VARCHAR(100) NOT NULL,\n",
    "                                stage VARCHAR(100) NOT NULL,\n",
    "                                start TIMESTAMP NOT NULL,\n",
    "                                end TIMESTAMP NOT NULL,\n",
    "                                duration FLOAT NOT NULL,\n",
    "                                experiment_id INTEGER NOT NULL,\n",
    "                                FOREIGN KEY (experiment_id) REFERENCES experiment (id)\n",
    "                                \n",
    "                            );\"\"\"\n",
    "\n",
    "\n",
    "# create / connect to db\n",
    "database = \"fibsem.db\"\n",
    "conn = create_connection(database)\n",
    "\n",
    "# create tables\n",
    "create_table(conn, SQL_CREATE_PROJECTS_TABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from autolamella import config as cfg\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from autolamella.structures import Experiment\n",
    "from autolamella.tools.data import calculate_statistics_dataframe\n",
    "\n",
    "EXPERIMENTS = [\n",
    "\"/home/patrick/github/autolamella/autolamella/log/HANNAH-WAFFLE-01-09082023\",\n",
    "\"/home/patrick/github/autolamella/autolamella/log/HANNAH-WAFFLE-02-09082023\",\n",
    "\"/home/patrick/github/autolamella/autolamella/log/HANNAH-WAFFLE-01-15082023\",\n",
    "]\n",
    "\n",
    "\n",
    "df_exp = pd.read_sql(\"SELECT * FROM experiments\", conn)\n",
    "display(df_exp)\n",
    "\n",
    "for PATH in EXPERIMENTS:\n",
    "    \n",
    "    print(PATH)   \n",
    "\n",
    "    dfs = calculate_statistics_dataframe(PATH)\n",
    "    df = dfs[1]\n",
    "\n",
    "    # format date as datetime\n",
    "    df[\"start\"] = pd.to_datetime(df[\"start\"], unit=\"s\")\n",
    "    df[\"start\"] = pd.to_datetime(df[\"start\"], utc=True)\n",
    "\n",
    "    df[\"end\"] = pd.to_datetime(df[\"start\"], unit=\"s\")\n",
    "    df[\"end\"] = pd.to_datetime(df[\"start\"], utc=True)\n",
    "\n",
    "\n",
    "    EXP_ID = df_exp[df_exp[\"name\"]==df[\"exp_name\"].iloc[0]][\"id\"].iloc[0]\n",
    "\n",
    "    print(EXP_ID)\n",
    "    df[\"experiment_id\"] = EXP_ID\n",
    "    # drop experiment_id\n",
    "    df = df.drop(columns=[\"exp_id\", \"exp_name\"])\n",
    "    \n",
    "    display(df)\n",
    "\n",
    "\n",
    "    df.to_sql('history', conn, if_exists='append', index = False)\n",
    "\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "SQL_CREATE_STEPS_TABLE = \"\"\"CREATE TABLE IF NOT EXISTS steps (\n",
    "                                id INTEGER PRIMARY KEY,\n",
    "                                petname VARCHAR(100) NOT NULL,\n",
    "                                stage VARCHAR(100) NOT NULL,\n",
    "                                step VARCHAR(100) NOT NULL,\n",
    "                                step_n INTEGER NOT NULL,\n",
    "                                timestamp TIMESTAMP NOT NULL,\n",
    "                                duration FLOAT NOT NULL,\n",
    "                                experiment_id INTEGER NOT NULL,\n",
    "                                FOREIGN KEY (experiment_id) REFERENCES experiment (id)\n",
    "                                \n",
    "                            );\"\"\"\n",
    "\n",
    "# create / connect to db\n",
    "database = \"fibsem.db\"\n",
    "conn = create_connection(database)\n",
    "\n",
    "# create tables\n",
    "create_table(conn, SQL_CREATE_STEPS_TABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from autolamella import config as cfg\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from autolamella.structures import Experiment\n",
    "from autolamella.tools.data import calculate_statistics_dataframe\n",
    "\n",
    "EXPERIMENTS = [\n",
    "\"/home/patrick/github/autolamella/autolamella/log/HANNAH-WAFFLE-01-09082023\",\n",
    "\"/home/patrick/github/autolamella/autolamella/log/HANNAH-WAFFLE-02-09082023\",\n",
    "\"/home/patrick/github/autolamella/autolamella/log/HANNAH-WAFFLE-01-15082023\",\n",
    "]\n",
    "\n",
    "\n",
    "df_exp = pd.read_sql(\"SELECT * FROM experiments\", conn)\n",
    "display(df_exp)\n",
    "\n",
    "for PATH in EXPERIMENTS:\n",
    "\n",
    "    dfs = calculate_statistics_dataframe(PATH)\n",
    "    df = dfs[3]\n",
    "\n",
    "    # display(df)\n",
    "    # # format date as datetime\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], unit=\"s\")\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True)\n",
    "\n",
    "    EXP_ID = df_exp[df_exp[\"name\"]==df[\"exp_name\"].iloc[0]][\"id\"].iloc[0]\n",
    "\n",
    "    print(EXP_ID)\n",
    "    df[\"experiment_id\"] = EXP_ID\n",
    "    # drop experiment_id\n",
    "    df = df.drop(columns=[\"exp_id\", \"exp_name\"])\n",
    "\n",
    "    # rename lamella to petname\n",
    "    df = df.rename(columns={\"lamella\": \"petname\"})\n",
    "\n",
    "    # replace NA with 0\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    display(df.head())\n",
    "\n",
    "    df.to_sql('steps', conn, if_exists='append', index = False)\n",
    "\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_CREATE_DETECTIONS_TABLE = \"\"\"CREATE TABLE IF NOT EXISTS detections (\n",
    "                                id INTEGER PRIMARY KEY,\n",
    "                                petname VARCHAR(100) NOT NULL,\n",
    "                                stage VARCHAR(100) NOT NULL,\n",
    "                                step VARCHAR(100) NOT NULL,\n",
    "                                feature VARCHAR(100) NOT NULL,\n",
    "                                dpx_x INTEGER NOT NULL,\n",
    "                                dpx_y INTEGER NOT NULL,\n",
    "                                dm_x FLOAT NOT NULL,\n",
    "                                dm_y FLOAT NOT NULL,\n",
    "                                is_correct BOOL NOT NULL,\n",
    "                                beam_type VARCHAR(100) NOT NULL,\n",
    "                                fname VARCHAR(100) NOT NULL,\n",
    "                                timestamp TIMESTAMP NOT NULL,\n",
    "                                experiment_id INTEGER NOT NULL,\n",
    "                                FOREIGN KEY (experiment_id) REFERENCES experiment (id)\n",
    "                                \n",
    "                            );\"\"\"\n",
    "\n",
    "# create / connect to db\n",
    "database = \"fibsem.db\"\n",
    "conn = create_connection(database)\n",
    "\n",
    "# create tables\n",
    "create_table(conn, SQL_CREATE_DETECTIONS_TABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from autolamella import config as cfg\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from autolamella.structures import Experiment\n",
    "from autolamella.tools.data import calculate_statistics_dataframe\n",
    "\n",
    "EXPERIMENTS = [\n",
    "\"/home/patrick/github/autolamella/autolamella/log/HANNAH-WAFFLE-01-09082023\",\n",
    "\"/home/patrick/github/autolamella/autolamella/log/HANNAH-WAFFLE-02-09082023\",\n",
    "\"/home/patrick/github/autolamella/autolamella/log/HANNAH-WAFFLE-01-15082023\",\n",
    "]\n",
    "\n",
    "\n",
    "df_exp = pd.read_sql(\"SELECT * FROM experiments\", conn)\n",
    "display(df_exp)\n",
    "\n",
    "\n",
    "# 4, stage\n",
    "# 5, detections\n",
    "# 6, interactions\n",
    "\n",
    "for PATH in EXPERIMENTS:\n",
    "\n",
    "    dfs = calculate_statistics_dataframe(PATH)\n",
    "    df = dfs[5]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # # display(df)\n",
    "    # # # format date as datetime\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], unit=\"s\")\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True)\n",
    "\n",
    "    EXP_ID = df_exp[df_exp[\"name\"]==df[\"exp_name\"].iloc[0]][\"id\"].iloc[0]\n",
    "\n",
    "    print(EXP_ID)\n",
    "    df[\"experiment_id\"] = EXP_ID\n",
    "    # # drop experiment_id\n",
    "    df = df.drop(columns=[\"exp_id\", \"exp_name\"])\n",
    "\n",
    "    # # rename lamella to petname\n",
    "    df = df.rename(columns={\"lamella\": \"petname\"})\n",
    "\n",
    "    # # replace NA with 0\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    display(df.head())\n",
    "\n",
    "    df.to_sql('detections', conn, if_exists='append', index = False)\n",
    "\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_CREATE_INTERACTIONS_TABLE = \"\"\"CREATE TABLE IF NOT EXISTS interactions (\n",
    "                                id INTEGER PRIMARY KEY,\n",
    "                                petname VARCHAR(100) NOT NULL,\n",
    "                                stage VARCHAR(100) NOT NULL,\n",
    "                                step VARCHAR(100) NOT NULL,\n",
    "                                type VARCHAR(100) NOT NULL,\n",
    "                                subtype VARCHAR(100) NOT NULL, \n",
    "                                dm_x FLOAT NOT NULL,\n",
    "                                dm_y FLOAT NOT NULL,\n",
    "                                beam_type VARCHAR(100) NOT NULL,\n",
    "                                timestamp TIMESTAMP NOT NULL,\n",
    "                                experiment_id INTEGER NOT NULL,\n",
    "                                FOREIGN KEY (experiment_id) REFERENCES experiment (id)\n",
    "                                \n",
    "                            );\"\"\"\n",
    "\n",
    "# create / connect to db\n",
    "database = \"fibsem.db\"\n",
    "conn = create_connection(database)\n",
    "\n",
    "# create tables\n",
    "create_table(conn, SQL_CREATE_INTERACTIONS_TABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from autolamella import config as cfg\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from autolamella.structures import Experiment\n",
    "from autolamella.tools.data import calculate_statistics_dataframe\n",
    "\n",
    "EXPERIMENTS = [\n",
    "\"/home/patrick/github/autolamella/autolamella/log/HANNAH-WAFFLE-01-09082023\",\n",
    "\"/home/patrick/github/autolamella/autolamella/log/HANNAH-WAFFLE-02-09082023\",\n",
    "\"/home/patrick/github/autolamella/autolamella/log/HANNAH-WAFFLE-01-15082023\",\n",
    "]\n",
    "\n",
    "\n",
    "df_exp = pd.read_sql(\"SELECT * FROM experiments\", conn)\n",
    "display(df_exp)\n",
    "\n",
    "\n",
    "# 4, stage\n",
    "# 5, detections\n",
    "# 6, interactions\n",
    "\n",
    "for PATH in EXPERIMENTS:\n",
    "\n",
    "    dfs = calculate_statistics_dataframe(PATH)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    df = dfs[6]\n",
    "    # # display(df)\n",
    "    # # # format date as datetime\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], unit=\"s\")\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True)\n",
    "\n",
    "    EXP_ID = df_exp[df_exp[\"name\"]==df[\"exp_name\"].iloc[0]][\"id\"].iloc[0]\n",
    "\n",
    "    # print(EXP_ID)\n",
    "    df[\"experiment_id\"] = EXP_ID\n",
    "    # # drop experiment_id\n",
    "    df = df.drop(columns=[\"exp_id\", \"exp_name\"])\n",
    "\n",
    "    # # rename lamella to petname\n",
    "    df = df.rename(columns={\"lamella\": \"petname\"})\n",
    "\n",
    "    # # replace NA with 0\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    display(df[df.type==\"MOVE\"].head())\n",
    "\n",
    "    # df.to_sql('interactions', conn, if_exists='append', index = False)\n",
    "\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload all data to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from autolamella import config as cfg\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from autolamella.structures import Experiment\n",
    "from autolamella.tools.data import calculate_statistics_dataframe\n",
    "\n",
    "\n",
    "import datetime\n",
    "import sqlite3\n",
    "from fibsem.db.util import *\n",
    "\n",
    "\n",
    "# create / connect to db\n",
    "database = \"fibsem.db\"\n",
    "conn = create_connection(database)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# return\n",
    "\n",
    "EXPERIMENTS = \"/home/patrick/github/autolamella/autolamella/log/HANNAH-WAFFLE-O1-170823\",\n",
    "\n",
    "for PATH in EXPERIMENTS:\n",
    "\n",
    "    print(PATH)   \n",
    "    print(\"-------EXPERIMENT-------\")\n",
    "\n",
    "    exp = Experiment.load(os.path.join(PATH, \"experiment.yaml\"))\n",
    "    df = exp.to_dataframe_v2()\n",
    "\n",
    "    # format date as datetime\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], unit=\"s\")\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], utc=True)\n",
    "\n",
    "    # drop experiment_id\n",
    "    df = df.drop(columns=[\"experiment_id\", \"num_lamella\"])\n",
    "    df[\"project_id\"] = 1\n",
    "    df[\"sample_id\"] = 1\n",
    "    df[\"user\"] = \"hannah\"\n",
    "    df[\"method\"] = \"waffle\"\n",
    "    \n",
    "    display(df)\n",
    "\n",
    "    # df.to_sql('experiments', conn, if_exists='append', index = False)\n",
    "\n",
    "    print(\"------------------\")\n",
    "\n",
    "    print(\"-----------DATABASE EXPERIMENTS -------\")\n",
    "    df_exp = pd.read_sql(\"SELECT * FROM experiments\", conn)\n",
    "    display(df_exp)\n",
    "    print(\"------------------\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    dfs = calculate_statistics_dataframe(PATH)\n",
    "\n",
    "    print(\"-------HISTORY----------\")\n",
    "    df = dfs[1]\n",
    "\n",
    "    # format date as datetime\n",
    "    df[\"start\"] = pd.to_datetime(df[\"start\"], unit=\"s\")\n",
    "    df[\"start\"] = pd.to_datetime(df[\"start\"], utc=True)\n",
    "\n",
    "    df[\"end\"] = pd.to_datetime(df[\"start\"], unit=\"s\")\n",
    "    df[\"end\"] = pd.to_datetime(df[\"start\"], utc=True)\n",
    "\n",
    "\n",
    "    EXP_ID = df_exp[df_exp[\"name\"]==df[\"exp_name\"].iloc[0]][\"id\"].iloc[0]\n",
    "\n",
    "    print(EXP_ID)\n",
    "    df[\"experiment_id\"] = EXP_ID\n",
    "    # drop experiment_id\n",
    "    df = df.drop(columns=[\"exp_id\", \"exp_name\"])\n",
    "    \n",
    "    display(df.head())\n",
    "\n",
    "\n",
    "    df.to_sql('history', conn, if_exists='append', index = False)\n",
    "\n",
    "    print(\"------------------\")\n",
    "\n",
    "\n",
    "    print(\"-------STEPS----------\")\n",
    "\n",
    "    df = dfs[3]\n",
    "    # display(df)\n",
    "    # # format date as datetime\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], unit=\"s\")\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True)\n",
    "\n",
    "    EXP_ID = df_exp[df_exp[\"name\"]==df[\"exp_name\"].iloc[0]][\"id\"].iloc[0]\n",
    "\n",
    "    print(EXP_ID)\n",
    "    df[\"experiment_id\"] = EXP_ID\n",
    "    # drop experiment_id\n",
    "    df = df.drop(columns=[\"exp_id\", \"exp_name\"])\n",
    "\n",
    "    # rename lamella to petname\n",
    "    df = df.rename(columns={\"lamella\": \"petname\"})\n",
    "\n",
    "    # replace NA with 0\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    display(df.head())\n",
    "\n",
    "    df.to_sql('steps', conn, if_exists='append', index = False)\n",
    "\n",
    "    print(\"------------------\")\n",
    "\n",
    "\n",
    "    print(\"-------DETECTIONS----------\")\n",
    "    df = dfs[5]\n",
    "\n",
    "    # # display(df)\n",
    "    # # # format date as datetime\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], unit=\"s\")\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True)\n",
    "\n",
    "    EXP_ID = df_exp[df_exp[\"name\"]==df[\"exp_name\"].iloc[0]][\"id\"].iloc[0]\n",
    "\n",
    "    print(EXP_ID)\n",
    "    df[\"experiment_id\"] = EXP_ID\n",
    "    # # drop experiment_id\n",
    "    df = df.drop(columns=[\"exp_id\", \"exp_name\"])\n",
    "\n",
    "    # # rename lamella to petname\n",
    "    df = df.rename(columns={\"lamella\": \"petname\"})\n",
    "\n",
    "    # # replace NA with 0\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    display(df.head())\n",
    "\n",
    "    df.to_sql('detections', conn, if_exists='append', index = False)\n",
    "\n",
    "    print(\"------------------\")\n",
    "\n",
    "\n",
    "    #### INTERACTIONS\n",
    "    print(\"-------INTERACTIONS----------\")\n",
    "    df = dfs[6]\n",
    "\n",
    "    # # # format date as datetime\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], unit=\"s\")\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True)\n",
    "\n",
    "    EXP_ID = df_exp[df_exp[\"name\"]==df[\"exp_name\"].iloc[0]][\"id\"].iloc[0]\n",
    "\n",
    "    # print(EXP_ID)\n",
    "    df[\"experiment_id\"] = EXP_ID\n",
    "    # # drop experiment_id\n",
    "    df = df.drop(columns=[\"exp_id\", \"exp_name\"])\n",
    "\n",
    "    # # rename lamella to petname\n",
    "    df = df.rename(columns={\"lamella\": \"petname\"})\n",
    "\n",
    "    # # replace NA with 0\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    display(df.head())\n",
    "\n",
    "    df.to_sql('interactions', conn, if_exists='append', index = False)\n",
    "\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fibsem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
