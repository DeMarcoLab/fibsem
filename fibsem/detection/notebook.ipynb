{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import glob\n",
    "from fibsem.segmentation.model import SegmentationModel\n",
    "import tifffile as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from random import shuffle\n",
    "\n",
    "import numpy as np\n",
    "from fibsem.detection.utils import Feature, FeatureType, DetectionResult\n",
    "from autoscript_sdb_microscope_client.structures import AdornedImage\n",
    "\n",
    "from fibsem.structures import Point\n",
    "from fibsem.imaging import masks\n",
    "from fibsem.detection import detection\n",
    "import skimage\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "from fibsem.segmentation.model import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection Goals\n",
    "\n",
    "\n",
    "1. Detect Needle Tip\n",
    "2. Detect Lamella Centre\n",
    "3. Detect Lamella Edges (Right / Left, Up / Down)\n",
    "\n",
    "account for multiple lamellas\n",
    "mask centre?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# data\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from fibsem import conversions\n",
    "\n",
    "\n",
    "filenames = glob.glob(\"/home/patrick/github/data/training/images/*.tif\")\n",
    "print(len(filenames))\n",
    "\n",
    "# model\n",
    "checkpoint = \"/home/patrick/github/fibsem/fibsem/segmentation/models/model.pt\"\n",
    "model = load_model(checkpoint)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DetectedFeatures:\n",
    "    features: list[Feature]\n",
    "    image: np.ndarray\n",
    "    mask: np.ndarray\n",
    "    pixelsize: float\n",
    "    distance: Point\n",
    "\n",
    "\n",
    "def to_bounding_box(contour):\n",
    "    # convert a contour to bounding box (xc, yc, w, h)\n",
    "    # ref : https://muthu.co/draw-bounding-box-around-contours-skimage/\n",
    "\n",
    "    xmin, xmax = np.min(contour[:, 1]), np.max(contour[:, 1])\n",
    "    ymin, ymax = np.min(contour[:, 0]), np.max(contour[:, 0])\n",
    "\n",
    "    w = (xmax - xmin)\n",
    "    h = (ymax - ymin)\n",
    "    xc = xmin + w // 2\n",
    "    yc = ymin + h // 2\n",
    "    \n",
    "    return [xc, yc, w, h]\n",
    "    \n",
    "\n",
    "def detect_features_v2(img: np.ndarray, mask: np.ndarray, features: tuple[Feature]) -> list[Feature]:\n",
    "\n",
    "    detection_features = []\n",
    "\n",
    "    for feature in features:\n",
    "        \n",
    "        det_type = feature.detection_type\n",
    "        initial_point = feature.feature_px\n",
    "        \n",
    "        if not isinstance(det_type, FeatureType):\n",
    "            raise TypeError(f\"Detection Type {det_type} is not supported.\")\n",
    "\n",
    "        # get the initial position estimate\n",
    "        if initial_point is None:\n",
    "            initial_point = Point(x=img.shape[1]//2, y=img.shape[0]//2)\n",
    "\n",
    "        if det_type == FeatureType.ImageCentre:\n",
    "            feature_px = initial_point\n",
    "\n",
    "        if det_type == FeatureType.NeedleTip:\n",
    "            feature_px = detection.detect_needle_v4(mask)\n",
    "\n",
    "        if det_type in [FeatureType.LamellaCentre, FeatureType.LamellaLeftEdge, FeatureType.LamellaRightEdge]:\n",
    "            feature_px = detection.detect_lamella(mask, det_type)\n",
    "\n",
    "        if det_type == FeatureType.LandingPost:\n",
    "            feature_px = detection.detect_landing_post_v3(img, initial_point)\n",
    "\n",
    "        detection_features.append(\n",
    "            Feature(detection_type=det_type, feature_px=feature_px)\n",
    "        )\n",
    "\n",
    "    return detection_features\n",
    "\n",
    "def locate_shift_between_features_v2(image: np.ndarray, model: SegmentationModel, features: tuple[Feature], pixelsize: float) -> DetectedFeatures:\n",
    "\n",
    "    # model inference\n",
    "    mask = model.inference(image)\n",
    "\n",
    "    # detect features \n",
    "    feature_1, feature_2 = detect_features_v2(image, mask, features)\n",
    "\n",
    "    # calculate distance between features\n",
    "    distance_px = conversions.distance_between_points(feature_1.feature_px, feature_2.feature_px)\n",
    "    distance_m = conversions.convert_point_from_pixel_to_metres(distance_px, pixelsize)\n",
    "\n",
    "    det = DetectedFeatures(\n",
    "        features=[feature_1, feature_2],\n",
    "        image = image,\n",
    "        mask = mask,\n",
    "        distance = distance_m,\n",
    "        pixelsize = pixelsize\n",
    "    )\n",
    "\n",
    "    return det\n",
    "\n",
    "def plot_det_result_v2(det: DetectedFeatures):\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 7))\n",
    "    ax[0].imshow(det.image, cmap=\"gray\")\n",
    "    ax[0].set_title(f\"Image\")\n",
    "    ax[1].imshow(det.mask)\n",
    "    ax[1].set_title(\"Prediction\")\n",
    "    ax[1].plot(det.features[0].feature_px.x, det.features[0].feature_px.y, \"g+\", ms=20, label=det.features[0].detection_type.name)\n",
    "    ax[1].plot(det.features[1].feature_px.x, det.features[1].feature_px.y, \"w+\", ms=20, label=det.features[1].detection_type.name)\n",
    "    ax[1].plot([det.features[0].feature_px.x, det.features[1].feature_px.x], [det.features[0].feature_px.y, det.features[1].feature_px.y], \"w--\")\n",
    "    ax[1].legend(loc=\"best\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# THINGS TO TRY:\n",
    "# masking centre area for lamella\n",
    "# using contours to extract individual lamellas -> pick centre\n",
    "\n",
    "\n",
    "shuffle(filenames)\n",
    "for i, fname in enumerate(filenames):\n",
    "\n",
    "    img = tf.imread(fname)\n",
    "\n",
    "    # inference\n",
    "    mask = model.inference(img)\n",
    "\n",
    "\n",
    "    # detect features\n",
    "    features = [Feature(FeatureType.NeedleTip), \n",
    "                    Feature(FeatureType.ImageCentre)]\n",
    "    det = locate_shift_between_features_v2(img, model, features=features, pixelsize=10e-9)\n",
    "\n",
    "    # plot\n",
    "    plot_det_result_v2(det)\n",
    "\n",
    "\n",
    "    if i == 5:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# mask helper\n",
    "\n",
    "\n",
    "# centre circle\n",
    "# left/right half\n",
    "# top/bottom half\n",
    "\n",
    "\n",
    "from fibsem.imaging import masks\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "arr = np.zeros(shape=(720, 1200 ))\n",
    "\n",
    "circ_mask = masks.create_circle_mask(arr.shape, radius=128)\n",
    "\n",
    "\n",
    "bl_mask = masks.get_area_mask(arr, left=True, lower=True)\n",
    "ul_mask = masks.get_area_mask(arr, left=True, upper=True)\n",
    "br_mask = masks.get_area_mask(arr, left=True, lower=True)\n",
    "ur_mask = masks.get_area_mask(arr, right=True, upper=True)\n",
    "mask = masks.get_area_mask(arr, left=True)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 5, figsize=(15, 7))\n",
    "ax[0].imshow(bl_mask)\n",
    "ax[1].imshow(ul_mask)\n",
    "ax[2].imshow(br_mask)\n",
    "ax[3].imshow(ur_mask)\n",
    "ax[4].imshow(mask)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contour stuff\n",
    "    # options for getting individual lamella from multiple: contours, masking \n",
    "    # bboxes = []\n",
    "    # contours = skimage.measure.find_contours(lamella_mask[:, :, 0].astype(np.uint8), 0.8)\n",
    "    # for contour in contours:\n",
    "    #     bboxes.append(to_bounding_box(contour))\n",
    "        # for contour in contours:\n",
    "    #     ax[1].plot(contour[:, 1], contour[:, 0], color=\"white\", linewidth=1)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('autoliftout')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0ae5a722a47a2a43262ee6d419b08874066f95ae58929cb636099b0410b63756"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
