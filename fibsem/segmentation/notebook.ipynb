{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dataset import preprocess_data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import torch\n",
    "\n",
    "data_path = \"/home/ubuntu/same_size/\"\n",
    "num_classes = 3\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating dataset...\n",
      "1227 images, 1227 labels\n",
      "finished validating dataset.\n",
      "Loading dataset from /home/ubuntu/same_size/ of length 1227\n",
      "Train dataset has 982 batches of size 1\n",
      "Validation dataset has 245 batches of size 1\n"
     ]
    }
   ],
   "source": [
    "train_data_loader, val_data_loader = preprocess_data(data_path, num_classes=num_classes, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([1, 1, 1536, 1024]) torch.Size([1, 1, 1536, 1024])\n",
      "[0. 1.]\n",
      "1 torch.Size([1, 1, 1536, 1024]) torch.Size([1, 1, 1536, 1024])\n",
      "[0. 1.]\n",
      "2 torch.Size([1, 1, 1536, 1024]) torch.Size([1, 1, 1536, 1024])\n",
      "[0. 1.]\n",
      "3 torch.Size([1, 1, 1536, 1024]) torch.Size([1, 1, 1536, 1024])\n",
      "[0. 1.]\n",
      "4 torch.Size([1, 1, 1536, 1024]) torch.Size([1, 1, 1536, 1024])\n",
      "[0. 1.]\n",
      "5 torch.Size([1, 1, 1536, 1024]) torch.Size([1, 1, 1536, 1024])\n",
      "[0. 1. 2.]\n",
      "6 torch.Size([1, 1, 1536, 1024]) torch.Size([1, 1, 1536, 1024])\n",
      "[0. 1.]\n",
      "7 torch.Size([1, 1, 1536, 1024]) torch.Size([1, 1, 1536, 1024])\n",
      "[0. 1. 2.]\n",
      "8 torch.Size([1, 1, 1536, 1024]) torch.Size([1, 1, 1536, 1024])\n",
      "[0. 1. 2.]\n",
      "9 torch.Size([1, 1, 1536, 1024]) torch.Size([1, 1, 1536, 1024])\n",
      "[0. 1.]\n",
      "10 torch.Size([1, 1, 1536, 1024]) torch.Size([1, 1, 1536, 1024])\n",
      "[0. 1.]\n",
      "11 torch.Size([1, 1, 1536, 1024]) torch.Size([1, 1, 1536, 1024])\n",
      "[0. 1.]\n",
      "12 torch.Size([1, 1, 1536, 1024]) torch.Size([1, 1, 1536, 1024])\n",
      "[0. 1.]\n",
      "13 torch.Size([1, 1, 1536, 1024]) torch.Size([1, 1, 1536, 1024])\n",
      "[0. 1.]\n",
      "14 torch.Size([1, 1, 1536, 1024]) torch.Size([1, 1, 1536, 1024])\n",
      "[0. 1.]\n",
      "15 torch.Size([1, 1, 1536, 1024]) torch.Size([1, 1, 1536, 1024])\n",
      "[0. 1. 2.]\n",
      "16 torch.Size([1, 1, 1536, 1024]) torch.Size([1, 1, 1536, 1024])\n",
      "[0. 1.]\n",
      "17 torch.Size([1, 1, 1536, 1024]) torch.Size([1, 1, 1536, 1024])\n",
      "[0. 1.]\n",
      "18 torch.Size([1, 1, 1536, 1024]) torch.Size([1, 1, 1536, 1024])\n",
      "[0. 1.]\n",
      "19 torch.Size([1, 1, 1536, 1024]) torch.Size([1, 1, 1536, 1024])\n",
      "[0. 1. 2.]\n",
      "20 torch.Size([1, 1, 1536, 1024]) torch.Size([1, 1, 1536, 1024])\n",
      "[0. 1.]\n",
      "21 torch.Size([1, 1, 1536, 1024]) torch.Size([1, 1, 1536, 1024])\n",
      "[0. 1.]\n",
      "22 torch.Size([1, 1, 1536, 1024]) torch.Size([1, 1, 1536, 1024])\n",
      "[0. 1.]\n",
      "23 torch.Size([1, 1, 1536, 1024]) torch.Size([1, 1, 1536, 1024])\n",
      "[0. 1.]\n",
      "24 torch.Size([1, 1, 1536, 1024]) torch.Size([1, 1, 1536, 1024])\n",
      "[0. 1.]\n",
      "25 torch.Size([1, 1, 1536, 1024]) torch.Size([1, 1, 1536, 1024])\n",
      "[0. 1. 2.]\n",
      "26 torch.Size([1, 1, 1536, 1024]) torch.Size([1, 1, 1536, 1024])\n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "for i, (img, mask) in enumerate(train_data_loader):\n",
    "\n",
    "    print(i, img.shape, mask.shape)\n",
    "    print(np.unique(mask))\n",
    "\n",
    "    # fig, ax = plt.subplots(1, 3, figsize=(5, 5))\n",
    "    # ax[0].imshow(img[0, 0], cmap=\"gray\")\n",
    "    # ax[1].imshow(mask[0, 0] == 1, cmap=\"gray\")\n",
    "    # ax[2].imshow(mask[0, 0] == 2, cmap=\"gray\")\n",
    "    # plt.show()\n",
    "\n",
    "    if i > 25:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unet(\n",
       "  (encoder): ResNetEncoder(\n",
       "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): UnetDecoder(\n",
       "    (center): Identity()\n",
       "    (blocks): ModuleList(\n",
       "      (0): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Identity()\n",
       "    (2): Activation(\n",
       "      (activation): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet18\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=1,  # grayscale images\n",
    "    classes=num_classes,  # background, needle, lamella\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "criterion = smp.losses.SoftCrossEntropyLoss()#torch.nn.CrossEntropyLoss()\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "epochs = 2 \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "WANDB= False\n",
    "from train import train\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# # training loop\n",
    "# for epoch in tqdm(range(epochs)):\n",
    "#         print(f\"------- Epoch {epoch+1} of {epochs}  --------\")\n",
    "        \n",
    "#         train(model, device, train_data_loader, criterion, optimizer, WANDB)\n",
    "#         # validate(model, device, val_data_loader, criterion, WANDB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 torch.int64\n",
      "torch.float32 torch.int64\n",
      "torch.float32 torch.int64\n",
      "torch.float32 torch.int64\n",
      "torch.float32 torch.int64\n",
      "torch.float32 torch.int64\n",
      "torch.float32 torch.int64\n"
     ]
    }
   ],
   "source": [
    "criterion = smp.losses.DiceLoss(mode=\"multiclass\")\n",
    "#smp.losses.SoftCrossEntropyLoss()#torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "for i, (images, masks) in enumerate(train_data_loader):\n",
    "    # set model to training mode\n",
    "    model.train()\n",
    "\n",
    "\n",
    "    images = images.to(device)\n",
    "    masks = masks.type(torch.LongTensor)\n",
    "    masks = masks.reshape(\n",
    "        masks.shape[0], masks.shape[2], masks.shape[3]\n",
    "    )  # remove channel dim\n",
    "    masks = masks.to(device)\n",
    "\n",
    "    outputs = model(images)#.to(device)\n",
    "    # pred = torch.argmax(outputs, dim=1)\n",
    "    \n",
    "    # print(images.shape, masks.shape, outputs.shape) #, pred.shape)\n",
    "    # print(\"output: \", torch.unique(outputs))\n",
    "    # print(\"pred: \", pred.shape, np.unique(pred.detach().cpu()))\n",
    "\n",
    "    # print(masks.device)\n",
    "    # print(pred.device) \n",
    "    # \n",
    "    print(outputs.dtype, masks.dtype)   \n",
    "\n",
    "    loss = criterion(outputs, masks)\n",
    "\n",
    "    # backwards pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # break\n",
    "    if i > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('autoliftout')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea78b76b2c840a5577de64ec81812954f7a3177bd4e73b9895b7933ce81940d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
