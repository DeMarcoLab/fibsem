{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "import tifffile as tf\n",
    "\n",
    "import os\n",
    "\n",
    "path = \"/home/patrick/github/data/liftout\"\n",
    "\n",
    "filenames = glob.glob(os.path.join(path, \"c3/**/label/*.tif*\"), recursive=True)\n",
    "\n",
    "print(len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in filenames[:10]:\n",
    "    img = tf.imread(fname)\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/home/patrick/github/data/liftout/training/c/images/\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "for i, fname in enumerate(filenames):\n",
    "    \n",
    "    img = tf.imread(fname)\n",
    "    new_fname = os.path.join(save_path,f\"c{i:05d}.tif\")\n",
    "    # print(new_fname)\n",
    "    tf.imsave(new_fname, img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filenames = sorted(glob.glob(os.path.join(save_path, \"*.tif\")))\n",
    "for fname in train_filenames:\n",
    "\n",
    "    img = tf.imread(fname)\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "\n",
    "images = zarr.open(tf.imread(os.path.join(\"/home/patrick/github/data/liftout/training/train\", \"images\", \"c*.tif*\"), aszarr=True)) \n",
    "labels = zarr.open(tf.imread(os.path.join(\"/home/patrick/github/data/liftout/training/train\", \"labels\",\"c*.tif*\"), aszarr=True))\n",
    "\n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "\n",
    "for img, label in zip(images, labels):\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ax[0].imshow(img, cmap=\"gray\")\n",
    "    ax[1].imshow(label)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import tifffile as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "images = sorted(glob.glob(os.path.join(\"/home/patrick/github/data/training/c/images\", \"*.tif*\")))\n",
    "labels = sorted(glob.glob(os.path.join(\"/home/patrick/github/data/training/c/labels\", \"*.tif*\")))\n",
    "\n",
    "for ii, (i, l) in enumerate(zip(images, labels)):\n",
    "    print(os.path.basename(i), os.path.basename(l))\n",
    "\n",
    "    img, lbl = tf.imread(i), tf.imread(l)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(7, 5))\n",
    "    ax[0].imshow(img, cmap=\"gray\")\n",
    "    ax[0].set_title(\"Image\")\n",
    "    ax[1].imshow(lbl)\n",
    "    ax[1].set_title(\"Label\")\n",
    "    plt.show()\n",
    "    \n",
    "    if ii == 2:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = sorted(glob.glob(os.path.join(\"/home/patrick/github/data/liftout/training/train/images/\", \"*.tif*\")))\n",
    "\n",
    "print(\"files: \", len(filenames))\n",
    "# filenames.append(*list(sorted(glob.glob(os.path.join(\"/home/patrick/github/data/training/train/images/\", \"*.tif*\")))\n",
    "print(\"files: \", len(filenames))\n",
    "import random\n",
    "random.shuffle(filenames)\n",
    "\n",
    "\n",
    "from fibsem.segmentation.model import SegmentationModel\n",
    "\n",
    "# baseline = \"/home/patrick/github/fibsem/fibsem/segmentation/models/model.pt\"\n",
    "# checkpoint_2 = \"/home/patrick/github/fibsem/fibsem/segmentation/models/03_11_2022_19_01_51_n08_model.pt\"\n",
    "# checkpoint_5 = \"/home/patrick/github/fibsem/fibsem/segmentation/models/03_11_2022_19_00_58_n05_model.pt\"\n",
    "# checkpoint_10 = \"/home/patrick/github/fibsem/fibsem/segmentation/models/03_11_2022_19_02_27_n10_model.pt\"\n",
    "# checkpoints = [baseline, checkpoint_2, checkpoint_5, checkpoint_10]\n",
    "\n",
    "# small_model = \"/home/patrick/github/fibsem/fibsem/segmentation/models/model2.pt\"\n",
    "# checkpoint_10 = \"/home/patrick/github/fibsem/fibsem/segmentation/models/combined/03_11_2022_20_00_10_n10_model.pt\"\n",
    "# checkpoint_15 = \"/home/patrick/github/fibsem/fibsem/segmentation/models/combined/03_11_2022_20_09_22_n15_model.pt\"\n",
    "# checkpoint_20 = \"/home/patrick/github/fibsem/fibsem/segmentation/models/combined/03_11_2022_20_18_32_n20_model.pt\"\n",
    "\n",
    "# checkpoint_10 = \"/home/patrick/github/fibsem/fibsem/segmentation/models/combined34/04_11_2022_18_37_32_n10_model.pt\"\n",
    "# checkpoint_15 = \"/home/patrick/github/fibsem/fibsem/segmentation/models/combined34/04_11_2022_18_46_48_n15_model.pt\"\n",
    "# checkpoint_20 = \"/home/patrick/github/fibsem/fibsem/segmentation/models/combined34/04_11_2022_18_56_00_n20_model.pt\"\n",
    "\n",
    "\n",
    "\n",
    "# Nov 21\n",
    "baseline = \"/home/patrick/github/fibsem/fibsem/segmentation/models/model2.pt\"\n",
    "\n",
    "checkpoint18_10 = \"/home/patrick/github/fibsem/fibsem/segmentation/models/c/18/21_11_2022_16_05_55_n10_model.pt\"\n",
    "checkpoint18_15 = \"/home/patrick/github/fibsem/fibsem/segmentation/models/c/18/21_11_2022_16_15_51_n15_model.pt\"\n",
    "checkpoint18_20 = \"/home/patrick/github/fibsem/fibsem/segmentation/models/c/18/21_11_2022_16_25_45_n20_model.pt\"\n",
    "\n",
    "checkpoint34_10 = \"/home/patrick/github/fibsem/fibsem/segmentation/models/c/34/21_11_2022_16_47_47_n10_model.pt\"\n",
    "checkpoint34_15 = \"/home/patrick/github/fibsem/fibsem/segmentation/models/c/34/21_11_2022_16_57_54_n15_model.pt\"\n",
    "checkpoint34_20 = \"/home/patrick/github/fibsem/fibsem/segmentation/models/c/34/21_11_2022_17_07_52_n20_model.pt\"\n",
    "\n",
    "checkpoints = [baseline, checkpoint18_10, checkpoint18_15, checkpoint18_20, checkpoint34_10, checkpoint34_15, checkpoint34_20]\n",
    "for i, fname in enumerate(filenames):\n",
    "\n",
    "    img = tf.imread(fname)\n",
    "\n",
    "    print(i, fname) \n",
    "\n",
    "    fig, ax = plt.subplots(1, len(checkpoints) + 1, figsize=(15, 5))\n",
    "    ax[0].imshow(img, cmap=\"gray\")\n",
    "    ax[0].set_title(\"Image\")\n",
    "\n",
    "\n",
    "    titles = [\"Baseline\", \"18_10\", \"18_15\", \"18_20\", \"34_10\", \"34_15\", \"34_20\"]\n",
    "    for j, (checkpoint, title) in enumerate(zip(checkpoints, titles), 1):\n",
    "        model = SegmentationModel(checkpoint=checkpoint, num_classes=3)\n",
    "\n",
    "        mask = model.inference(img)\n",
    "\n",
    "        ax[j].imshow(mask)\n",
    "        ax[j].set_title(title)\n",
    "\n",
    "    save_path = \"training/c\"\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    fig.savefig(os.path.join(save_path, f\"{os.path.basename(fname).replace('tif', 'png')}\"))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import glob\n",
    "from fibsem.detection import detection\n",
    "\n",
    "from fibsem.detection.utils import FeatureType\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# create ones image\n",
    "img = np.ones((1024, 1536, 3))\n",
    "\n",
    "img[200:800, 500:1000, 0] = 255\n",
    "img[200:800, 500:1000, 1] = 0\n",
    "img[200:800, 500:1000, 2] = 0\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "lamella_edge = detection.detect_lamella(img, FeatureType.LamellaCentre, mask_radius=180)\n",
    "\n",
    "print(lamella_edge)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"files: \", len(filenames))\n",
    "# filenames.append(*list(sorted(glob.glob(os.path.join(\"/home/patrick/github/data/training/train/images/\", \"*.tif*\")))\n",
    "print(\"files: \", len(filenames))\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "from fibsem.segmentation.model import SegmentationModel\n",
    "from fibsem.imaging import masks\n",
    "import tifffile as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nov 21\n",
    "baseline = \"/home/patrick/github/fibsem/fibsem/segmentation/models/model2.pt\"\n",
    "checkpoint18_20 = \"/home/patrick/github/fibsem/fibsem/segmentation/models/c/18/21_11_2022_16_25_45_n20_model.pt\"\n",
    "checkpoint34_20 = \"/home/patrick/github/fibsem/fibsem/segmentation/models/c/34/21_11_2022_17_07_52_n20_model.pt\"\n",
    "\n",
    "filenames = sorted(glob.glob(os.path.join(\"/home/patrick/github/data/liftout/training/train/images/\", \"*.tif*\")))\n",
    "random.shuffle(filenames)\n",
    "\n",
    "# checkpoints = [baseline, checkpoint18_20, checkpoint34_20]\n",
    "model = SegmentationModel(checkpoint=checkpoint34_20, num_classes=3)\n",
    "\n",
    "\n",
    "# filenames = [\"/home/patrick/github/data/liftout/training/train/images/00136.tif\"]\n",
    "for i, fname in enumerate(filenames):\n",
    "\n",
    "    img = tf.imread(fname)\n",
    "\n",
    "    print(i, fname) \n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15, 7))\n",
    "    ax[0].imshow(img, cmap=\"gray\")\n",
    "    ax[0].set_title(\"Image\")\n",
    "\n",
    "    k = 1\n",
    "\n",
    "    mask = model.inference(img)\n",
    "\n",
    "    color = (255, 0, 0)\n",
    "    mask_radius = 256\n",
    "    # lamella_mask, _ = detection.extract_class_pixels(mask, color)\n",
    "    # mask = masks.apply_circular_mask(lamella_mask, radius=mask_radius)\n",
    "\n",
    "\n",
    "\n",
    "    # need to check actually if lamella is present\n",
    "\n",
    "\n",
    "    try:\n",
    "\n",
    "        centre = detection.detect_lamella_v2(mask, FeatureType.LamellaCentre, color=color, mask_radius=mask_radius)\n",
    "        left = detection.detect_lamella_v2(mask, FeatureType.LamellaLeftEdge, color=color, mask_radius=mask_radius)\n",
    "        right = detection.detect_lamella_v2(mask, FeatureType.LamellaRightEdge, color=color, mask_radius=mask_radius)\n",
    "        # centre = detection.get_mask_point(mask, \"centre\", \"centre\")\n",
    "        # left = detection.get_mask_point(mask, \"left\", \"centre\")\n",
    "        # right = detection.get_mask_point(mask, \"right\", \"centre\")\n",
    "        # upper = detection.get_mask_point(mask, \"centre\", \"upper\")\n",
    "        # lower = detection.get_mask_point(mask, \"centre\", \"lower\")\n",
    "        # top_left = detection.get_mask_point(mask, \"left\", \"upper\")\n",
    "        # top_right = detection.get_mask_point(mask, \"right\", \"upper\")\n",
    "        # bottom_left = detection.get_mask_point(mask, \"left\", \"lower\")\n",
    "        # bottom_right = detection.get_mask_point(mask, \"right\", \"lower\")\n",
    "\n",
    "        ax[k].set_title(\"Mask\")\n",
    "        ax[k].imshow(mask)\n",
    "        ax[k].scatter(centre.x, centre.y, color=\"white\", label=\"centre\")\n",
    "        ax[k].scatter(left.x, left.y, color=\"green\", label=\"left\")\n",
    "        ax[k].scatter(right.x, right.y, color=\"blue\", label=\"right\")\n",
    "        # ax[k].scatter(upper.x, upper.y, color=\"orange\", label=\"upper\")\n",
    "        # ax[k].scatter(lower.x, lower.y, color=\"purple\", label=\"lower\")\n",
    "        # ax[k].scatter(top_left.x, top_left.y, color=\"black\", label=\"top left\")\n",
    "        # ax[k].scatter(top_right.x, top_right.y, color=\"grey\", label=\"top right\")\n",
    "        # ax[k].scatter(bottom_left.x, bottom_left.y, color=\"pink\", label=\"bottom left\")\n",
    "        # ax[k].scatter(bottom_right.x, bottom_right.y, color=\"yellow\", label=\"bottom right\")\n",
    "        ax[k].legend()\n",
    "\n",
    "        # save figure\n",
    "        save_path = \"training/det_c\"\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        fig.savefig(os.path.join(save_path, f\"{os.path.basename(fname).replace('tif', 'png')}\"))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('autoliftout')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea78b76b2c840a5577de64ec81812954f7a3177bd4e73b9895b7933ce81940d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
