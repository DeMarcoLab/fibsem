{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "import tifffile as tf\n",
    "\n",
    "import os\n",
    "\n",
    "path = \"/home/patrick/github/data\"\n",
    "\n",
    "filenames = glob.glob(os.path.join(path, \"dm*/**/*.tif*\"), recursive=True)\n",
    "\n",
    "print(len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter lamella, landing\n",
    "\n",
    "print(len(filenames))\n",
    "# filenames = [fname for fname in filenames if \"ref_landing\" not in fname and \"ref_lamella\" not in fname and \"trench\" not in fname and \"low_res\" not in fname]\n",
    "\n",
    "filenames = [fname for fname in filenames if \"needle\" in fname]\n",
    "print(len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in filenames[:10]:\n",
    "    img = tf.imread(fname)\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/home/patrick/github/data/training\"\n",
    "for i, fname in enumerate(filenames):\n",
    "    \n",
    "    img = tf.imread(fname)\n",
    "    new_fname = os.path.join(save_path,f\"a{i:05d}.tif\")\n",
    "\n",
    "    tf.imsave(new_fname, img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filenames = sorted(glob.glob(os.path.join(save_path, \"*.tif\")))\n",
    "for fname in train_filenames[:10]:\n",
    "\n",
    "    img = tf.imread(fname)\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "\n",
    "images = zarr.open(tf.imread(os.path.join(\"/home/patrick/github/data/training/\", \"images\", \"*.tif*\"), aszarr=True)) \n",
    "labels = zarr.open(tf.imread(os.path.join(\"/home/patrick/github/data/training/\", \"labels\",\"*.tif*\"), aszarr=True))\n",
    "\n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "\n",
    "for img, label in zip(images, labels):\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ax[0].imshow(img, cmap=\"gray\")\n",
    "    ax[1].imshow(label)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import tifffile as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "images = sorted(glob.glob(os.path.join(\"/home/patrick/github/data/training/train/images\", \"*.tif*\")))\n",
    "labels = sorted(glob.glob(os.path.join(\"/home/patrick/github/data/training/train/labels\", \"*.tif*\")))\n",
    "\n",
    "for ii, (i, l) in enumerate(zip(images, labels)):\n",
    "    print(os.path.basename(i), os.path.basename(l))\n",
    "\n",
    "    img, lbl = tf.imread(i), tf.imread(l)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(7, 5))\n",
    "    ax[0].imshow(img, cmap=\"gray\")\n",
    "    ax[0].set_title(\"Image\")\n",
    "    ax[1].imshow(lbl)\n",
    "    ax[1].set_title(\"Label\")\n",
    "    plt.show()\n",
    "    \n",
    "    if ii == 2:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = sorted(glob.glob(os.path.join(\"/home/patrick/github/data/liftout/training/train/images/\", \"*.tif*\")))\n",
    "\n",
    "print(\"files: \", len(filenames))\n",
    "# filenames.append(*list(sorted(glob.glob(os.path.join(\"/home/patrick/github/data/training/train/images/\", \"*.tif*\")))\n",
    "print(\"files: \", len(filenames))\n",
    "import random\n",
    "random.shuffle(filenames)\n",
    "\n",
    "\n",
    "from fibsem.segmentation.model import SegmentationModel\n",
    "\n",
    "baseline = \"/home/patrick/github/fibsem/fibsem/segmentation/models/model.pt\"\n",
    "# checkpoint_2 = \"/home/patrick/github/fibsem/fibsem/segmentation/models/03_11_2022_19_01_51_n08_model.pt\"\n",
    "# checkpoint_5 = \"/home/patrick/github/fibsem/fibsem/segmentation/models/03_11_2022_19_00_58_n05_model.pt\"\n",
    "# checkpoint_10 = \"/home/patrick/github/fibsem/fibsem/segmentation/models/03_11_2022_19_02_27_n10_model.pt\"\n",
    "# checkpoints = [baseline, checkpoint_2, checkpoint_5, checkpoint_10]\n",
    "\n",
    "small_model = \"/home/patrick/github/fibsem/fibsem/segmentation/models/model2.pt\"\n",
    "# checkpoint_10 = \"/home/patrick/github/fibsem/fibsem/segmentation/models/combined/03_11_2022_20_00_10_n10_model.pt\"\n",
    "# checkpoint_15 = \"/home/patrick/github/fibsem/fibsem/segmentation/models/combined/03_11_2022_20_09_22_n15_model.pt\"\n",
    "# checkpoint_20 = \"/home/patrick/github/fibsem/fibsem/segmentation/models/combined/03_11_2022_20_18_32_n20_model.pt\"\n",
    "\n",
    "checkpoint_10 = \"/home/patrick/github/fibsem/fibsem/segmentation/models/combined34/04_11_2022_18_37_32_n10_model.pt\"\n",
    "checkpoint_15 = \"/home/patrick/github/fibsem/fibsem/segmentation/models/combined34/04_11_2022_18_46_48_n15_model.pt\"\n",
    "checkpoint_20 = \"/home/patrick/github/fibsem/fibsem/segmentation/models/combined34/04_11_2022_18_56_00_n20_model.pt\"\n",
    "\n",
    "\n",
    "checkpoints = [baseline, small_model, checkpoint_10, checkpoint_15, checkpoint_20]\n",
    "for i, fname in enumerate(filenames):\n",
    "\n",
    "    img = tf.imread(fname)\n",
    "\n",
    "    print(i, fname) \n",
    "\n",
    "    fig, ax = plt.subplots(1, len(checkpoints) + 1, figsize=(15, 5))\n",
    "    ax[0].imshow(img, cmap=\"gray\")\n",
    "    ax[0].set_title(\"Image\")\n",
    "\n",
    "\n",
    "    titles = [\"Baseline\", \"Update\", \"Checkpoint 10\", \"Checkpoint 15\", \"Checkpoint 20\"]\n",
    "    for j, (checkpoint, title) in enumerate(zip(checkpoints, titles), 1):\n",
    "        model = SegmentationModel(checkpoint=checkpoint, num_classes=3)\n",
    "\n",
    "        mask = model.inference(img)\n",
    "\n",
    "        ax[j].imshow(mask)\n",
    "        ax[j].set_title(title)\n",
    "\n",
    "    save_path = \"results34\"\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    fig.savefig(os.path.join(save_path, f\"{os.path.basename(fname).replace('tif', 'png')}\"))\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('autoliftout')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea78b76b2c840a5577de64ec81812954f7a3177bd4e73b9895b7933ce81940d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
