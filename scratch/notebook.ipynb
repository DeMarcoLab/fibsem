{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "import tifffile as tf\n",
    "\n",
    "import os\n",
    "\n",
    "path = \"/home/patrick/github/data\"\n",
    "\n",
    "filenames = glob.glob(os.path.join(path, \"dm*/**/*.tif*\"), recursive=True)\n",
    "\n",
    "print(len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter lamella, landing\n",
    "\n",
    "print(len(filenames))\n",
    "# filenames = [fname for fname in filenames if \"ref_landing\" not in fname and \"ref_lamella\" not in fname and \"trench\" not in fname and \"low_res\" not in fname]\n",
    "\n",
    "filenames = [fname for fname in filenames if \"needle\" in fname]\n",
    "print(len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in filenames[:10]:\n",
    "    img = tf.imread(fname)\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/home/patrick/github/data/training\"\n",
    "for i, fname in enumerate(filenames):\n",
    "    \n",
    "    img = tf.imread(fname)\n",
    "    new_fname = os.path.join(save_path,f\"a{i:05d}.tif\")\n",
    "\n",
    "    tf.imsave(new_fname, img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filenames = sorted(glob.glob(os.path.join(save_path, \"*.tif\")))\n",
    "for fname in train_filenames[:10]:\n",
    "\n",
    "    img = tf.imread(fname)\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "\n",
    "images = zarr.open(tf.imread(os.path.join(\"/home/patrick/github/data/training/\", \"images\", \"*.tif*\"), aszarr=True)) \n",
    "labels = zarr.open(tf.imread(os.path.join(\"/home/patrick/github/data/training/\", \"labels\",\"*.tif*\"), aszarr=True))\n",
    "\n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "\n",
    "for img, label in zip(images, labels):\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ax[0].imshow(img, cmap=\"gray\")\n",
    "    ax[1].imshow(label)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import tifffile as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "images = sorted(glob.glob(os.path.join(\"/home/patrick/github/data/training/train/images\", \"*.tif*\")))\n",
    "labels = sorted(glob.glob(os.path.join(\"/home/patrick/github/data/training/train/labels\", \"*.tif*\")))\n",
    "\n",
    "for ii, (i, l) in enumerate(zip(images, labels)):\n",
    "    print(os.path.basename(i), os.path.basename(l))\n",
    "\n",
    "    img, lbl = tf.imread(i), tf.imread(l)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(7, 5))\n",
    "    ax[0].imshow(img, cmap=\"gray\")\n",
    "    ax[0].set_title(\"Image\")\n",
    "    ax[1].imshow(lbl)\n",
    "    ax[1].set_title(\"Label\")\n",
    "    plt.show()\n",
    "    \n",
    "    if ii == 2:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = sorted(glob.glob(os.path.join(\"/home/patrick/github/data/liftout/training/train/images/\", \"*.tif*\")))\n",
    "\n",
    "print(\"files: \", len(filenames))\n",
    "# filenames.append(*list(sorted(glob.glob(os.path.join(\"/home/patrick/github/data/training/train/images/\", \"*.tif*\")))\n",
    "print(\"files: \", len(filenames))\n",
    "import random\n",
    "random.shuffle(filenames)\n",
    "\n",
    "\n",
    "from fibsem.segmentation.model import SegmentationModel\n",
    "\n",
    "baseline = \"/home/patrick/github/fibsem/fibsem/segmentation/models/model.pt\"\n",
    "# checkpoint_2 = \"/home/patrick/github/fibsem/fibsem/segmentation/models/03_11_2022_19_01_51_n08_model.pt\"\n",
    "# checkpoint_5 = \"/home/patrick/github/fibsem/fibsem/segmentation/models/03_11_2022_19_00_58_n05_model.pt\"\n",
    "# checkpoint_10 = \"/home/patrick/github/fibsem/fibsem/segmentation/models/03_11_2022_19_02_27_n10_model.pt\"\n",
    "# checkpoints = [baseline, checkpoint_2, checkpoint_5, checkpoint_10]\n",
    "\n",
    "small_model = \"/home/patrick/github/fibsem/fibsem/segmentation/models/model2.pt\"\n",
    "# checkpoint_10 = \"/home/patrick/github/fibsem/fibsem/segmentation/models/combined/03_11_2022_20_00_10_n10_model.pt\"\n",
    "# checkpoint_15 = \"/home/patrick/github/fibsem/fibsem/segmentation/models/combined/03_11_2022_20_09_22_n15_model.pt\"\n",
    "# checkpoint_20 = \"/home/patrick/github/fibsem/fibsem/segmentation/models/combined/03_11_2022_20_18_32_n20_model.pt\"\n",
    "\n",
    "checkpoint_10 = \"/home/patrick/github/fibsem/fibsem/segmentation/models/combined34/04_11_2022_18_37_32_n10_model.pt\"\n",
    "checkpoint_15 = \"/home/patrick/github/fibsem/fibsem/segmentation/models/combined34/04_11_2022_18_46_48_n15_model.pt\"\n",
    "checkpoint_20 = \"/home/patrick/github/fibsem/fibsem/segmentation/models/combined34/04_11_2022_18_56_00_n20_model.pt\"\n",
    "\n",
    "\n",
    "checkpoints = [baseline, small_model, checkpoint_10, checkpoint_15, checkpoint_20]\n",
    "for i, fname in enumerate(filenames):\n",
    "\n",
    "    img = tf.imread(fname)\n",
    "\n",
    "    print(i, fname) \n",
    "\n",
    "    fig, ax = plt.subplots(1, len(checkpoints) + 1, figsize=(15, 5))\n",
    "    ax[0].imshow(img, cmap=\"gray\")\n",
    "    ax[0].set_title(\"Image\")\n",
    "\n",
    "\n",
    "    titles = [\"Baseline\", \"Update\", \"Checkpoint 10\", \"Checkpoint 15\", \"Checkpoint 20\"]\n",
    "    for j, (checkpoint, title) in enumerate(zip(checkpoints, titles), 1):\n",
    "        model = SegmentationModel(checkpoint=checkpoint, num_classes=3)\n",
    "\n",
    "        mask = model.inference(img)\n",
    "\n",
    "        ax[j].imshow(mask)\n",
    "        ax[j].set_title(title)\n",
    "\n",
    "    save_path = \"results34\"\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    fig.savefig(os.path.join(save_path, f\"{os.path.basename(fname).replace('tif', 'png')}\"))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from fibsem import utils, patterning\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# protocol_path = \"/home/patrick/github/autoliftout/liftout/protocol/protocol.yaml\"\n",
    "protocol_path = r\"C:\\Users\\pcle0002\\Documents\\repos\\autoliftout\\liftout\\protocol\\protocol.yaml\"\n",
    "microscope, settings = utils.setup_session(protocol_path=protocol_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns_fn = {f\"{pattern.name}\": pattern for pattern in patterning.__PATTERNS__}\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(patterns_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fibsem.structures import FibsemPatternSettings, FibsemPattern\n",
    "\n",
    "rect_pattern = patterns_fn[\"Rectangle\"]()\n",
    "\n",
    "rp = rect_pattern.define(protocol={\"pattern\": \"Rectangle\", \"width\": 10e-6, \"height\": 5e-6, \n",
    "                                              \"depth\": 2e-6, \"rotation\": 0, \n",
    "                                              \"centre_x\": 0, \"centre_y\": 0, \n",
    "                                              \"scan_direction\": \"TopToBottom\", \"cleaning_cross_section\": True})\n",
    "\n",
    "\n",
    "print(rp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "pattern_fn = patterns_fn[\"Trench\"]()\n",
    "print(pattern_fn.required_keys)\n",
    "pattern = pattern_fn.define(protocol=settings.protocol[\"polish_lamella\"])\n",
    "\n",
    "pprint(pattern)\n",
    "\n",
    "print(\"---------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in patterns_fn:\n",
    "    print(p, patterns_fn[p], patterns_fn[p]())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test AutoFOCUS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from fibsem import utils, calibration, patterning\n",
    "from fibsem.structures import BeamType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "microscope, settings = utils.setup_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default\n",
    "calibration.auto_focus_beam(microscope, settings, beam_type=BeamType.ELECTRON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = microscope.get(\"working_distance\", BeamType.ELECTRON)\n",
    "print(f\"working distance: {wd:2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sharpness\n",
    "from fibsem.calibration import _sharpness, _dog\n",
    "calibration.auto_focus_beam(microscope=microscope, settings=settings, \n",
    "                            beam_type=BeamType.ELECTRON, \n",
    "                            metric_fn=_sharpness, kwargs={\"disk_size\": 5}, \n",
    "                            num_steps=20, step_size=0.05e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration.auto_focus_beam(microscope, settings, beam_type=BeamType.ELECTRON, metric_fn=_dog, num_steps=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = wd\n",
    "wd1 = microscope.get(\"working_distance\", BeamType.ELECTRON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"working distance: {wd:2e}\") # default\n",
    "print(f\"working distance: {wd1:2e}\") # fibsem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings.image.beam_type = BeamType.ELECTRON\n",
    "settings.image.save = True\n",
    "\n",
    "from fibsem import acquire\n",
    "\n",
    "microscope.set(\"working_distance\", wd, BeamType.ELECTRON)\n",
    "settings.image.label = \"default_autofocus\"\n",
    "eb_image = acquire.new_image(microscope, settings.image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "microscope.set(\"working_distance\", wd1, BeamType.ELECTRON)\n",
    "settings.image.label = \"fibsem_autofocus\"\n",
    "eb_image = acquire.new_image(microscope, settings.image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "wds = np.linspace(3.5e-3, 4.5e-3, 20)\n",
    "\n",
    "settings.image.save = True\n",
    "settings.image.save_path = r\"C:\\Users\\Admin\\Github\\fibsem\\demo_2023-03-13-10-27-17AM\"\n",
    "\n",
    "for wd in wds:\n",
    "    print(f\"wd_{wd:.4e}\".replace('.', '_'))\n",
    "    microscope.set(\"working_distance\", wd, BeamType.ELECTRON)\n",
    "    settings.image.label = f\"wd_{wd:.4e}\".replace('.', '_')\n",
    "    eb_image = acquire.new_image(microscope, settings.image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulator Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from fibsem import utils, acquire, movement\n",
    "\n",
    "from fibsem.structures import BeamType, FibsemManipulatorPosition\n",
    "\n",
    "\n",
    "microscope, settings = utils.setup_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# microscope.insert_manipulator()\n",
    "settings.image.hfw = 400e-6\n",
    "images = acquire.take_reference_images(microscope, settings.image)\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 7))\n",
    "ax[0].imshow(images[0].data, cmap=\"gray\")\n",
    "ax[0].set_title(\"Electron Image 01\")\n",
    "ax[1].imshow(images[1].data, cmap=\"gray\")\n",
    "ax[1].set_title(\"IOn Image 02\")\n",
    "plt.show()\n",
    "\n",
    "# #position = FibsemManipulatorPosition(x=20e-6, y=20e-6, z=20e-6, r=0, t=0)\n",
    "# microscope.move_manipulator_corrected(dx = 20e-6, dy = 20e-6, beam_type=BeamType.ELECTRON)\n",
    "position = FibsemManipulatorPosition(z=20e-6)\n",
    "microscope.move_manipulator_to_position_offset(position, name=\"EUCENTRIC\")\n",
    "\n",
    "images_new = acquire.take_reference_images(microscope, settings.image)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 7))\n",
    "ax[0].imshow(images_new[0].data, cmap=\"gray\")\n",
    "ax[0].set_title(\"Electron Image 01\")\n",
    "ax[1].imshow(images_new[1].data, cmap=\"gray\")\n",
    "ax[1].set_title(\"IOn Image 02\")\n",
    "plt.show()\n",
    "microscope.get_manipulator_position()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gas Injection System\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from fibsem.structures import BeamType\n",
    "\n",
    "from fibsem import utils, acquire, movement\n",
    "\n",
    "microscope, settings = utils.setup_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fibsem import gis\n",
    "\n",
    "print(gis.gis_protocol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gis.sputter_platinum(microscope, gis.gis_protocol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gis.cryo_sputter(microscope, gis.gis_protocol, name=\"cryo_sputter_eb_grid_01\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulator Position Testing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from fibsem import utils, acquire\n",
    "from fibsem.structures import BeamType, FibsemManipulatorPosition, FibsemStagePosition\n",
    "\n",
    "from liftout import actions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "microscope, settings = utils.setup_session(manufacturer=\"Thermo\", ip_address=\"10.0.0.1\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "microscope.retract_manipulator()\n",
    "\n",
    "settings.image.hfw = 400e-6\n",
    "\n",
    "# eb_image, ib_image = acquire.take_reference_images(microscope, settings.image)\n",
    "# fig, ax = plt.subplots(1, 2, figsize=(10, 7))\n",
    "# ax[0].imshow(eb_image.data, cmap=\"gray\")\n",
    "# ax[1].imshow(ib_image.data, cmap=\"gray\")\n",
    "# plt.show()\n",
    "\n",
    "actions.move_needle_to_liftout_position(microscope)\n",
    "\n",
    "eb_image, ib_image = acquire.take_reference_images(microscope, settings.image)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 7))\n",
    "ax[0].imshow(eb_image.data, cmap=\"gray\")\n",
    "ax[1].imshow(ib_image.data, cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "actions.move_needle_to_landing_position(microscope)\n",
    "\n",
    "eb_image, ib_image = acquire.take_reference_images(microscope, settings.image)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 7))\n",
    "ax[0].imshow(eb_image.data, cmap=\"gray\")\n",
    "ax[1].imshow(ib_image.data, cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "actions.move_needle_to_reset_position(microscope)\n",
    "\n",
    "eb_image, ib_image = acquire.take_reference_images(microscope, settings.image)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 7))\n",
    "ax[0].imshow(eb_image.data, cmap=\"gray\")\n",
    "ax[1].imshow(ib_image.data, cmap=\"gray\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tile Image Collection\n",
    "\n",
    "- Collect tiled images\n",
    "- Stitch Together\n",
    "- Update metadata\n",
    "- Click to Move, Save Positions from Image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from fibsem import utils, acquire\n",
    "from fibsem.structures import BeamType, FibsemManipulatorPosition, FibsemStagePosition\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from fibsem.imaging import _tile\n",
    "\n",
    "microscope, settings = utils.setup_session(manufacturer=\"Thermo\", ip_address=\"10.0.0.1\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_state = microscope.get_current_microscope_state()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(start_state.eb_settings.working_distance)\n",
    "print(microscope.get_current_microscope_state().eb_settings.working_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "microscope.set_microscope_state(start_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "PATH = os.path.join(os.getcwd(), \"tile-images\")\n",
    "os.makedirs(PATH, exist_ok=True)\n",
    "\n",
    "\n",
    "GRID_SIZE = 400e-6\n",
    "TILE_SIZE = 50e-6\n",
    "BEAM_TYPE = BeamType.ELECTRON\n",
    "RESOLUTION = [1024, 1024]\n",
    "\n",
    "\n",
    "settings.image.hfw = TILE_SIZE\n",
    "settings.image.beam_type = BEAM_TYPE\n",
    "settings.image.save = True\n",
    "settings.image.save_path = PATH\n",
    "settings.image.resolution = RESOLUTION\n",
    "settings.image.dwell_time = 1e-6\n",
    "settings.image.autocontrast = False\n",
    "\n",
    "ddict = _tile._tile_image_collection(microscope, settings, GRID_SIZE, TILE_SIZE)\n",
    "images = ddict[\"images\"]\n",
    "big_image = ddict[\"big_image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # stitch a composite image from 2d array of images\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "image = _tile._stitch_images(images=images, ddict=ddict, overlap=0)\n",
    "\n",
    "# plot stitched and big image\n",
    "fig, ax = plt.subplots(1, 2, figsize=(30, 15))\n",
    "ax[0].imshow(image.data, cmap=\"gray\")\n",
    "ax[0].set_title(\"Stitched Image\")\n",
    "ax[1].imshow(big_image.data, cmap=\"gray\")\n",
    "ax[1].set_title(\"Big Image\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# TODO: more advanced version where we read the metadata to get the relative position of each image in space\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from fibsem import config as cfg\n",
    "PATH = os.path.join(cfg.DATA_PATH, \"tile\")\n",
    "from fibsem.structures import FibsemImage\n",
    "\n",
    "image = FibsemImage.load(os.path.join(PATH, \"stitched_image.tif\"))\n",
    "\n",
    "print(image.metadata.microscope_state.absolute_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Intersecting Circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from fibsem import utils, acquire\n",
    "from fibsem.structures import BeamType, FibsemManipulatorPosition, FibsemStagePosition\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random circles on image\n",
    "\n",
    "import cv2\n",
    "image = np.zeros((1024, 1024))\n",
    "image2 = np.zeros((1024, 1024))\n",
    "\n",
    "r = 50\n",
    "for i in range(25):\n",
    "    x = np.random.randint(0, 1024)\n",
    "    y = np.random.randint(0, 1024)\n",
    "    \n",
    "    image = cv2.circle(image, (x, y), r, (1, 1, 1), -1)\n",
    "    \n",
    "    x = np.random.randint(0, 1024)\n",
    "    y = np.random.randint(0, 1024)\n",
    "    \n",
    "    image2 = cv2.circle(image2, (x, y), r, (1, 1, 1), -1)\n",
    "\n",
    "\n",
    "\n",
    "print(image.shape)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10, 7))\n",
    "ax[0].imshow(image, cmap=\"Greens\")\n",
    "ax[0].axis(\"off\")\n",
    "ax[1].imshow(image2, cmap=\"Reds\")\n",
    "ax[1].axis(\"off\")\n",
    "ax[2].imshow(image, cmap=\"Greens\", alpha=0.5)\n",
    "ax[2].imshow(image2, cmap=\"Reds\", alpha=0.5)\n",
    "ax[2].axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# detect where circles intersect\n",
    "\n",
    "from skimage import measure\n",
    "\n",
    "intersection = image + image2\n",
    "intersection[intersection < 2] = 0\n",
    "intersection[intersection == 2] = 1\n",
    "\n",
    "\n",
    "# extract contour from intersection\n",
    "\n",
    "contours = measure.find_contours(intersection, 0.8)\n",
    "\n",
    "# plot intersection and contour\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 7))\n",
    "ax[0].imshow(intersection, cmap=\"gray\")\n",
    "ax[0].axis(\"off\")\n",
    "ax[1].imshow(image, cmap=\"Greens\", alpha=0.5)\n",
    "ax[1].imshow(image2, cmap=\"Reds\", alpha=0.5)\n",
    "ax[1].axis(\"off\")\n",
    "for contour in contours:\n",
    "    ax[1].plot(contour[:, 1], contour[:, 0], linewidth=2)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = intersection\n",
    "idxs = np.unique(mask)\n",
    "\n",
    "for idx in idxs:\n",
    "    if idx==0:\n",
    "        continue\n",
    "\n",
    "    # create a new image\n",
    "    feature_mask = np.zeros_like(mask)\n",
    "    feature_mask[mask==idx] = 1\n",
    "\n",
    "    # detect features\n",
    "    feature.detect(image, feature_mask)\n",
    "    features.append(deepcopy(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from fibsem.segmentation.model import SegmentationModel, load_model\n",
    "from fibsem.imaging import _tile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "image = np.zeros(shape=(1024*4, 1024*4))\n",
    "image.shape\n",
    "\n",
    "model = load_model(\"/home/patrick/github/fibsem/fibsem/segmentation/models/model4.pt\", \"resnet34\", 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.inference(image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(out)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cut image into tiles and predict on each tile\n",
    "\n",
    "\n",
    "n_rows, n_cols = 4, 4\n",
    "tile_size = 1024\n",
    "overlap = 0\n",
    "tiles = _tile._create_tiles(image, n_rows, n_cols, tile_size, overlap=0)\n",
    "\n",
    "\n",
    "# reshape \n",
    "print(tiles.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.inference(tiles, rgb=False)\n",
    "print(out.shape)\n",
    "\n",
    "# reshape output \n",
    "out = out.reshape(n_rows, n_cols, tile_size, tile_size)\n",
    "\n",
    "# re-stitch together?\n",
    "from fibsem.imaging import _tile\n",
    "arr = _tile._stitch_arr(out)\n",
    "\n",
    "# plot stitched and big image\n",
    "fig, ax = plt.subplots(1, 2, figsize=(30, 15))\n",
    "ax[0].imshow(arr, cmap=\"gray\")\n",
    "ax[0].set_title(\"Stitched Image\")\n",
    "ax[1].imshow(image, cmap=\"gray\")\n",
    "ax[1].set_title(\"Big Image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point Reprojection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fibsem import utils, acquire\n",
    "from fibsem.structures import FibsemImage, BeamType, FibsemStagePosition, Point\n",
    "\n",
    "from fibsem.imaging import _tile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "microscope, settings = utils.setup_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r\"C:\\Users\\Admin\\Github\\fibsem\\fibsem\\log\\data\\tile\\stitched-image-electron.tif\"\n",
    "\n",
    "image = FibsemImage.load(PATH)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# microscope._safe_absolute_stage_movement(image.metadata.microscope_state.absolute_position)\n",
    "current_position = microscope.get_stage_position()\n",
    "current_point = _calculate_repojection(image, current_position)\n",
    "positions.append(current_position)\n",
    "print(\"---------------------------------------\")\n",
    "base_position = image.metadata.microscope_state.absolute_position\n",
    "base_point = _calculate_repojection(image, base_position)\n",
    "\n",
    "\n",
    "# plot on matplotlib\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "plt.imshow(image.data, cmap=\"gray\")\n",
    "\n",
    "\n",
    "COLOURS = [\"r+\", \"g+\", \"b+\", \"c+\", \"m+\", \"y+\"]\n",
    "points = _reproject_positions(image, positions)\n",
    "# plt.plot(current_point.x, current_point.y, \"r+\", ms=100, markeredgewidth=5, label=\"current_position\")\n",
    "for i, pt in enumerate(points):\n",
    "    plt.plot(pt.x, pt.y, COLOURS[i], ms=100, markeredgewidth=5, label=f\"position_{i}\")\n",
    "\n",
    "plt.plot(base_point.x, base_point.y, \"w+\", ms=100, markeredgewidth=5 , label=\"base position\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions.pop(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points\n",
    "\n",
    "for pt in points:\n",
    "    # reverse to list\n",
    "    pt = pt.y, pt.x\n",
    "    print(pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(positions + [current_position])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# draw positions on image\n",
    "\n",
    "from fibsem import utils, conversions\n",
    "from fibsem.imaging import _tile\n",
    "from fibsem.structures import Point, FibsemStagePosition, FibsemImage\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "PATH = r\"C:\\Users\\Admin\\Github\\fibsem\\fibsem\\log\\data\\tile\\stitched-image-ion.tif\"\n",
    "POS_PATH = r\"C:\\Users\\Admin\\Github\\fibsem\\fibsem\\log\\data\\tile\\stitched-image-ion-positions.yaml\"\n",
    "\n",
    "\n",
    "image = FibsemImage.load(PATH)\n",
    "\n",
    "pdict = utils.load_yaml(POS_PATH)\n",
    "positions = [FibsemStagePosition.__from_dict__(p) for p in pdict]\n",
    "\n",
    "fig = _tile._plot_positions(image, positions, show=False)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Feature Detections as Positions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "microscope, settings = utils.setup_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the point in image coord\n",
    "coords = Point(500, 500)\n",
    "\n",
    "\n",
    "_new_position = _tile._convert_image_coord_to_position(microscope, settings, image, coords)\n",
    "pprint(_new_position) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import cv2\n",
    "mask_r = np.zeros_like(image.data)\n",
    "mask_b = np.zeros_like(image.data)\n",
    "\n",
    "\n",
    "N_CELLS = 25\n",
    "r = 125\n",
    "for i in range(N_CELLS):\n",
    "    x = np.random.randint(0, mask_r.shape[1])\n",
    "    y = np.random.randint(0, mask_r.shape[0])\n",
    "    \n",
    "    mask_r = cv2.circle(mask_r, (x, y), r, (1, 1, 1), -1)\n",
    "    \n",
    "    x = np.random.randint(0, mask_b.shape[1])\n",
    "    y = np.random.randint(0, mask_b.shape[0])\n",
    "    \n",
    "    mask_b = cv2.circle(mask_b, (x, y), r, (1, 1, 1), -1)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20, 15))\n",
    "\n",
    "ax[0].imshow(image.data, cmap=\"gray\", alpha=0.7)\n",
    "ax[0].imshow(mask_r, cmap=\"Reds\", alpha=0.3)\n",
    "ax[0].imshow(mask_b, cmap=\"Blues\", alpha=0.3)\n",
    "ax[0].axis(\"off\")\n",
    "ax[1].imshow(mask_r, cmap=\"Reds\")\n",
    "ax[1].axis(\"off\")\n",
    "ax[2].imshow(mask_b, cmap=\"Blues\")\n",
    "ax[2].axis(\"off\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from fibsem.detection import detection\n",
    "from fibsem.segmentation.utils import decode_segmap\n",
    "\n",
    "\n",
    "\n",
    "INTERSECTION =  True\n",
    "\n",
    "if INTERSECTION:\n",
    "    intersection = detection._calculate_intersection([mask_r, mask_b])\n",
    "    mask = intersection\n",
    "else:\n",
    "    mask = mask_r\n",
    "\n",
    "\n",
    "features = [detection.CoreFeature()]\n",
    "positions, features = detection._detect_positions(microscope, settings, image, mask, features)\n",
    "\n",
    "pprint(positions)\n",
    "pprint(features)\n",
    "\n",
    "det = detection.DetectedFeatures(\n",
    "    features=features, # type: ignore\n",
    "    image=image.data,\n",
    "    mask=mask,\n",
    "    rgb=decode_segmap(mask, 5),\n",
    "    pixelsize=image.metadata.pixel_size.x,\n",
    ")\n",
    "\n",
    "detection.plot_detection(det)\n",
    "fig = _tile._plot_positions(image, positions, show=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from fibsem import utils, acquire\n",
    "from fibsem.structures import FibsemImage\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "PATH = r\"C:\\Users\\Admin\\Github\\autolamella\\autolamella\\log\\HANNAH-WAFFLE-26072023\\overview-image-ion.tif\"\n",
    "image = FibsemImage.load(PATH)\n",
    "\n",
    "image_auto_gamma = acquire.auto_gamma(image, method=\"autogamma\")\n",
    "image_auto_clahe = acquire.auto_gamma(image, method=\"clahe\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20, 15))\n",
    "ax[0].imshow(image.data, cmap=\"gray\")\n",
    "ax[0].set_title(\"Original\")\n",
    "ax[1].imshow(image_auto_gamma.data, cmap=\"gray\")\n",
    "ax[1].set_title(\"Auto Gamma\")\n",
    "ax[2].imshow(image_auto_clahe.data, cmap=\"gray\")\n",
    "ax[2].set_title(\"Auto CLAHE\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "image_auto_gamma.save(r\"C:\\Users\\Admin\\Github\\autolamella\\autolamella\\log\\HANNAH-WAFFLE-26072023/overviewe-image-ion-auto-gamma.tif\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from fibsem.detection import detection\n",
    "from fibsem.segmentation.model import load_model\n",
    "from fibsem.structures import FibsemImage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "PATH = \"/home/patrick/github/data/autolamella/train2\"\n",
    "filenames = sorted(glob.glob(os.path.join(PATH, \"*.tif\")))\n",
    "\n",
    "CHECKPOINT_OPENFIBSEM = \"/home/patrick/github/fibsem/fibsem/segmentation/models/model4.pt\"\n",
    "CHECKPOINT_AUTOLAMELLA_1 = \"/home/patrick/github/fibsem/fibsem/segmentation/models/autolamella/autolamella-baseline-34.pt\"\n",
    "CHECKPOINT_AUTOLAMELLA_2 = \"/home/patrick/github/fibsem/fibsem/segmentation/models/autolamella/model.pt\"\n",
    "\n",
    "CHECKPOINTS = [CHECKPOINT_OPENFIBSEM, CHECKPOINT_AUTOLAMELLA_1, CHECKPOINT_AUTOLAMELLA_2]\n",
    "# CHECKPOINTS = [CHECKPOINT_AUTOLAMELLA_2]\n",
    "for fname in filenames:\n",
    "    \n",
    "    img = FibsemImage.load(fname)\n",
    "\n",
    "    features = [detection.LamellaCentre()]\n",
    "    dets = []\n",
    "    for i, CHECKPOINT in enumerate(CHECKPOINTS):\n",
    "\n",
    "        model = load_model(CHECKPOINT, encoder=\"resnet34\", nc=3)\n",
    "\n",
    "        det  = detection.detect_features(img.data, model, features=features, pixelsize=25e-9, filter=False)\n",
    "        dets.append(det)\n",
    "    \n",
    "    print(fname)\n",
    "    detection.plot_detections(dets, titles=[\"OpenFIBSEM Baseline\", \"AutoLamella 01\", \"AutoLamella 02\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/home/patrick/github/data/autolamella/train2\"\n",
    "filenames = sorted(glob.glob(os.path.join(PATH, \"*.tif\")))\n",
    "\n",
    "CHECKPOINT = \"/home/patrick/github/fibsem/fibsem/segmentation/models/autolamella/autolamella-02-34.pt\"\n",
    "\n",
    "features = [detection.LamellaCentre(), detection.LamellaTopEdge(), detection.LamellaBottomEdge()]\n",
    "for fname in filenames:\n",
    "    print(fname)\n",
    "    img = FibsemImage.load(fname)\n",
    "\n",
    "    model = load_model(CHECKPOINT, encoder=\"resnet34\", nc=3)\n",
    "\n",
    "    det  = detection.detect_features(img.data, model, features=features, pixelsize=25e-9, filter=False)\n",
    "    \n",
    "    detection.plot_detection(det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from fibsem.structures import FibsemImage\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "import shutil\n",
    "\n",
    "PATH = \"/home/patrick/github/data/liftout/train-new/\"\n",
    "TRAIN_PATH = os.path.join(PATH, \"train\")\n",
    "TEST_PATH = os.path.join(PATH, \"test\")\n",
    "\n",
    "\n",
    "os.makedirs(TRAIN_PATH, exist_ok=True)\n",
    "os.makedirs(TEST_PATH, exist_ok=True)\n",
    "\n",
    "# copy files to train folder\n",
    "\n",
    "\n",
    "count = 0\n",
    "for SAMPLE in [\"dm-embryo\", \"celegans\", \"yeast\"]:\n",
    "\n",
    "    filenames = glob.glob(os.path.join(PATH, SAMPLE, \"*.tif\"))\n",
    "    shuffle(filenames)\n",
    "\n",
    "    print(f\"Found {len(filenames)} images for {SAMPLE}\")\n",
    "    count += len(filenames)\n",
    "    for i, fname in enumerate(filenames):\n",
    "        print(i, f\"{SAMPLE}-{os.path.basename(fname)}\")\n",
    "        # img = FibsemImage.load(fname)\n",
    "        # plt.imshow(img.data, cmap=\"gray\")\n",
    "        # plt.show()\n",
    "\n",
    "        # copy file to\n",
    "        if i < 200:\n",
    "            shutil.copy(fname, os.path.join(TRAIN_PATH, f\"{SAMPLE}-{os.path.basename(fname)}\"))\n",
    "        elif i < 250:\n",
    "            shutil.copy(fname, os.path.join(TEST_PATH, f\"{SAMPLE}-{os.path.basename(fname)}\"))\n",
    "        else:\n",
    "            break\n",
    "\n",
    "\n",
    "print(f\"Found {count} images in total\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reprojected Positions (Rotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "from fibsem import utils, acquire\n",
    "from fibsem.imaging import _tile\n",
    "from fibsem.structures import FibsemImage\n",
    "from autolamella.structures import Experiment\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from fibsem.structures import FibsemStagePosition\n",
    "\n",
    "PATH = r\"C:\\Users\\Admin\\Github\\autolamella\\autolamella\\log\\HANNAH-WAFFLE-O1-170823\"\n",
    "\n",
    "IB_FNAME = \"ref_MillTrench_final_low_res_ib.tif\"\n",
    "EB_FNAME = \"ref_MillUndercut_start_eb.tif\"\n",
    "\n",
    "exp = Experiment.load(os.path.join(PATH, \"experiment.yaml\"))\n",
    "\n",
    "\n",
    "trench_positions = []\n",
    "undercut_positions = []\n",
    "eb_images = []\n",
    "ib_images = []\n",
    "for i, lamella in enumerate(exp.positions):\n",
    "    for state in lamella.history:\n",
    "        if state.stage.name == \"MillUndercut\":\n",
    "            undercut_positions.append(state.microscope_state.absolute_position)\n",
    "            undercut_positions[-1].name = f\"{lamella._petname}\"\n",
    "\n",
    "        if state.stage.name == \"MillTrench\":\n",
    "            trench_positions.append(state.microscope_state.absolute_position)\n",
    "            trench_positions[-1].name = f\"{lamella._petname}\"\n",
    "\n",
    "    image = FibsemImage.load(os.path.join(PATH, lamella._petname, EB_FNAME))\n",
    "    eb_images.append(image)\n",
    "    image = FibsemImage.load(os.path.join(PATH, lamella._petname, IB_FNAME))\n",
    "    ib_images.append(image)\n",
    "\n",
    "\n",
    "# transformed_positions = []\n",
    "# for i, pos in enumerate(positions):\n",
    "#     tpos = _tile._transform_position(pos)\n",
    "#     transformed_positions.append(tpos)\n",
    "\n",
    "\n",
    "# TODO: automate logic for when to transform positions, based on image\n",
    "\n",
    "for eb_image, ib_image in list(zip(eb_images, ib_images))[:2]:\n",
    "    print(\"---PROJECTING TRENCH POSITIONS----\")\n",
    "    print(\"--------- ELECTRON IMAGE ---------\")\n",
    "    fig = _tile._plot_positions(eb_image, positions=trench_positions, _clip=True, _bound=True)\n",
    "    plt.show()\n",
    "    print(\"-------\")   \n",
    "\n",
    "    print(\"--------- ION IMAGE ---------\")\n",
    "    fig = _tile._plot_positions(ib_image, positions=trench_positions, _clip=True, _bound=True)\n",
    "    plt.show()\n",
    "    print(\"-------\") \n",
    "\n",
    "\n",
    "    print(\"---PROJECTING UNDERCUT POSITIONS----\")\n",
    "    print(\"--------- ELECTRON IMAGE ---------\")\n",
    "    fig = _tile._plot_positions(eb_image, positions=undercut_positions, _clip=True, _bound=True)\n",
    "    plt.show()\n",
    "    print(\"-------\")\n",
    "    print(\"--------- ION IMAGE ---------\")\n",
    "    fig = _tile._plot_positions(ib_image, positions=undercut_positions, _clip=True, _bound=True)\n",
    "    plt.show()\n",
    "    print(\"-------\") \n",
    "    \n",
    "\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fully automated target detection and tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fibsem.segmentation.model import load_model\n",
    "from fibsem.detection import detection\n",
    "\n",
    "image = eb_images[8]\n",
    "model = load_model(\"autolamella-03-34.pt\", encoder=\"resnet34\")\n",
    "\n",
    "# point, reproj\n",
    "\n",
    "# reproject points, filter out those that are not in the image\n",
    "reprojected_points = _tile._reproject_positions(image, trench_positions, _bound=True)\n",
    "print(f\"Reprojected positions: {len(reprojected_points)}\")\n",
    "\n",
    "# detect all matching lamella centres in the image \n",
    "dets = []\n",
    "for pos in reprojected_points:\n",
    "\n",
    "    det = detection.detect_features(image.data, model, features=[detection.LamellaCentre()], \n",
    "        pixelsize=image.metadata.pixel_size.x, filter=True, point=pos)\n",
    "\n",
    "    dets.append(det)\n",
    "\n",
    "# plot original points and detections\n",
    "_names = [pt.name for pt in reprojected_points]\n",
    "fig = _tile._plot_positions(image,  [pos for pos in trench_positions if pos.name in _names])\n",
    "plt.show()\n",
    "\n",
    "fig = detection.plot_detections(dets, titles=[pos.name for pos in reprojected_points])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### WAFFLE LIFTOUT DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from fibsem.structures import FibsemImage\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "import shutil\n",
    "\n",
    "EXP_PATH = \"/home/patrick/github/data/EXPERIMENTS/AUTOLIFTOUT-WAFFLE-01-24082023\"\n",
    "\n",
    "PATH = \"/home/patrick/github/data/liftout/train-waffle\"\n",
    "TRAIN_PATH = os.path.join(PATH, \"train\")\n",
    "TEST_PATH = os.path.join(PATH, \"test\")\n",
    "\n",
    "\n",
    "os.makedirs(TRAIN_PATH, exist_ok=True)\n",
    "os.makedirs(TEST_PATH, exist_ok=True)\n",
    "\n",
    "# copy files to train folder\n",
    "\n",
    "filenames = glob.glob(os.path.join(EXP_PATH, \"**/ml-*.tif\"), recursive=True)\n",
    "shuffle(filenames)\n",
    "\n",
    "SPLIT = 0.9\n",
    "print(f\"Found {len(filenames)} images for {os.path.basename(EXP_PATH)}\")\n",
    "# count += len(filenames)\n",
    "for i, fname in enumerate(filenames):\n",
    "    print(i, f\"{os.path.basename(fname)}\")\n",
    "\n",
    "    # img = FibsemImage.load(fname)\n",
    "    # plt.imshow(img.data, cmap=\"gray\")\n",
    "    # plt.show()\n",
    "\n",
    "    if i < int(len(filenames) * SPLIT):\n",
    "        shutil.copy(fname, os.path.join(TRAIN_PATH, f\"{os.path.basename(fname)}\"))\n",
    "    else:\n",
    "        shutil.copy(fname, os.path.join(TEST_PATH, f\"{os.path.basename(fname)}\"))\n",
    "\n",
    "    # shutil.copy(fname, os.path.join(TRAIN_PATH, f\"{SAMPLE}-{os.path.basename(fname)}\"))\n",
    "\n",
    "\n",
    "# print(f\"Found {count} images in total\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from fibsem.detection import detection\n",
    "from fibsem.segmentation.model import load_model\n",
    "from fibsem.structures import FibsemImage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "PATH = \"/home/patrick/github/data/liftout/train-waffle/train\"\n",
    "filenames = sorted(glob.glob(os.path.join(PATH, \"*.tif\")))\n",
    "\n",
    "print(f\"Found {len(filenames)} images (train)\")\n",
    "\n",
    "TEST_PATH = \"/home/patrick/github/data/liftout/train-waffle/test\"\n",
    "test_filenames = sorted(glob.glob(os.path.join(TEST_PATH, \"*.tif\")))\n",
    "print(f\"Found {len(test_filenames)} images (test)\")\n",
    "\n",
    "filenames += test_filenames\n",
    "\n",
    "\n",
    "\n",
    "CHECKPOINT_OPENFIBSEM = \"openfibsem-baseline-34.pt\"\n",
    "CHECKPOINT_WAFFLE_00  = \"/home/patrick/github/fibsem/fibsem/segmentation/models/autoliftout/waffle/e10/model04.pt\"\n",
    "CHECKPOINT_WAFFLE_02  = \"/home/patrick/github/fibsem/fibsem/segmentation/models/autoliftout/waffle/e10/model09.pt\"\n",
    "CHECKPOINT_WAFFLE_04  = \"/home/patrick/github/fibsem/fibsem/segmentation/models/autoliftout/waffle/e10/model14.pt\"\n",
    "CHECKPOINT_WAFFLE_05  = \"/home/patrick/github/fibsem/fibsem/segmentation/models/autoliftout/waffle/e10/model19.pt\"\n",
    "\n",
    "CHECKPOINTS = [CHECKPOINT_OPENFIBSEM, CHECKPOINT_WAFFLE_00, CHECKPOINT_WAFFLE_02, CHECKPOINT_WAFFLE_04, CHECKPOINT_WAFFLE_05]\n",
    "\n",
    "\n",
    "for j, fname in enumerate(filenames):\n",
    "    \n",
    "    img = FibsemImage.load(fname)\n",
    "\n",
    "    features = [detection.NeedleTip(), detection.LamellaCentre()]\n",
    "    dets = []\n",
    "    for i, CHECKPOINT in enumerate(CHECKPOINTS):\n",
    "\n",
    "        model = load_model(CHECKPOINT, encoder=\"resnet34\", nc=3)\n",
    "\n",
    "        det  = detection.detect_features(img.data, model, features=features, pixelsize=25e-9, filter=True)\n",
    "        dets.append(det)\n",
    "    \n",
    "    print(f\"({j}/{len(filenames)}) {fname}\")\n",
    "    detection.plot_detections(dets, titles=[os.path.basename(checkpoint) for checkpoint in CHECKPOINTS])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EVAL ON IMAGES ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from fibsem.detection import detection\n",
    "from fibsem.segmentation.model import load_model\n",
    "from fibsem.structures import FibsemImage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "TEST_PATH = \"/home/patrick/github/data/liftout/train-new/test\"\n",
    "filenames = sorted(glob.glob(os.path.join(TEST_PATH, \"*.tif\")))[:30]\n",
    "print(f\"Found {len(filenames)} images (test)\")\n",
    "\n",
    "\n",
    "\n",
    "CHECKPOINTS = [\n",
    "    \"openfibsem-baseline-34.pt\", \n",
    "    \"/home/patrick/github/fibsem/fibsem/segmentation/models/autoliftout/new-base/e20/model09.pt\",\n",
    "    \"/home/patrick/github/fibsem/fibsem/segmentation/models/autoliftout/new-base/e20/model14.pt\",\n",
    "    \"/home/patrick/github/fibsem/fibsem/segmentation/models/autoliftout/new-base/e20/model19.pt\",\n",
    "    \"/home/patrick/github/fibsem/fibsem/segmentation/models/autoliftout/new-base/e20/model24.pt\",\n",
    "    \"/home/patrick/github/fibsem/fibsem/segmentation/models/autoliftout/new-base/e20/model29.pt\",\n",
    "]\n",
    "\n",
    "\n",
    "for j, fname in enumerate(filenames):\n",
    "    \n",
    "    img = FibsemImage.load(fname)\n",
    "\n",
    "    features = [detection.NeedleTip(), detection.LamellaCentre()]\n",
    "    dets = []\n",
    "    for i, CHECKPOINT in enumerate(CHECKPOINTS):\n",
    "\n",
    "        model = load_model(CHECKPOINT, encoder=\"resnet34\", nc=3)\n",
    "\n",
    "        det  = detection.detect_features(img.data, model, features=features, pixelsize=25e-9, filter=True)\n",
    "        dets.append(det)\n",
    "    \n",
    "    print(f\"({j}/{len(filenames)}) {fname}\")\n",
    "    detection.plot_detections(dets, titles=[os.path.basename(checkpoint) for checkpoint in CHECKPOINTS])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BASELINE ON DM-EMBRYO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from fibsem.detection import evaluation\n",
    "\n",
    "\n",
    "# ground truth (user corrections)\n",
    "DATA_PATH = \"/home/patrick/github/data/liftout/active-learning/train/dm-embryo/data3.csv\"\n",
    "\n",
    "\n",
    "# eval checkpoints\n",
    "# BASELINE\n",
    "CHECKPOINTS = [\n",
    "    {\"checkpoint\": \"openfibsem-01-18.pt\", \"encoder\": \"resnet18\", \"nc\": 3},\n",
    "    {\"checkpoint\": \"openfibsem-02-18.pt\", \"encoder\": \"resnet18\", \"nc\": 3},\n",
    "    {\"checkpoint\": \"openfibsem-03-18.pt\", \"encoder\": \"resnet18\", \"nc\": 3},\n",
    "    {\"checkpoint\": \"openfibsem-baseline-34.pt\", \"encoder\": \"resnet34\", \"nc\": 3},\n",
    "]\n",
    "\n",
    "\n",
    "# inputs\n",
    "# ground truth dataframe\n",
    "# test data filenames\n",
    "# eval checkpoints\n",
    "\n",
    "# test data\n",
    "TEST_PATH = \"/home/patrick/github/data/liftout/active-learning/train/dm-embryo/images/\"\n",
    "filenames = sorted(glob.glob(os.path.join(TEST_PATH, \"*.tif\")))\n",
    "print(f\"Found {len(filenames)} images (test)\")\n",
    "\n",
    "\n",
    "SAVE_PATH = \"/home/patrick/github/data/liftout/paper/eval/dm-embryo\"\n",
    "df_eval = evaluation._run_evaluation(DATA_PATH, filenames, CHECKPOINTS, plot=True, _clip=False, save=True, save_path=SAVE_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display(df_eval)\n",
    "\n",
    "category_orders = {\"checkpoint\": [\"openfibsem-01-18\", \"openfibsem-02-18\", \"openfibsem-03-18\", \"openfibsem-baseline-34\"], \n",
    "                    \"feature\": [\"LamellaCentre\", \"LamellaLeftEdge\", \"LamellaRightEdge\", \"NeedleTip\"]}\n",
    "evaluation._plot_evalution_data(df_eval, thresholds=[250, 100, 50, 25, 10], category_orders=category_orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.to_csv(\"/home/patrick/github/fibsem/scratch/active-learning/autoliftout/baseline/eval.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from fibsem.detection import detection\n",
    "from fibsem.segmentation.model import load_model\n",
    "from fibsem.structures import FibsemImage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "from fibsem.structures import Point\n",
    "from fibsem.detection import detection\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "\n",
    "from tqdm import tqdm\n",
    "from fibsem.detection import evaluation\n",
    "\n",
    "# ground truth (user corrections)\n",
    "DATA_PATH = \"/home/patrick/github/data/ML_LOG/data.csv\"\n",
    "\n",
    "# WAFFLE\n",
    "CHECKPOINTS = [\n",
    "    {\"checkpoint\": \"openfibsem-baseline-34.pt\", \"encoder\": \"resnet34\", \"nc\": 3},\n",
    "    # {\"checkpoint\": \"autoliftout-finetune-34.pt\", \"encoder\": \"resnet34\", \"nc\": 3},\n",
    "    {\"checkpoint\": \"autoliftout-waffle-01-34.pt\", \"encoder\": \"resnet34\", \"nc\": 3},\n",
    "    # {\"checkpoint\": \"/home/patrick/github/fibsem/fibsem/segmentation/models/autoliftout/waffle/aug/finetune/model10.pt\", \"encoder\": \"resnet50\", \"nc\": 3},\n",
    "]\n",
    "\n",
    "\n",
    "# TRAIN_PATH = \"/home/patrick/github/data/liftout/train-waffle/train\"\n",
    "# filenames = sorted(glob.glob(os.path.join(TRAIN_PATH, \"*.tif\")))\n",
    "# print(f\"Found {len(filenames)} images (train)\")\n",
    "\n",
    "# test data\n",
    "TEST_PATH = \"/home/patrick/github/data/liftout/train-waffle/test\"\n",
    "filenames = sorted(glob.glob(os.path.join(TEST_PATH, \"*.tif\")))\n",
    "print(f\"Found {len(filenames)} images (test)\")\n",
    "\n",
    "SAVE_PATH = SAVE_PATH = \"/home/patrick/github/data/liftout/paper/eval/autoliftout-waffle/test\"\n",
    "df_eval = evaluation._run_evaluation(DATA_PATH, filenames, CHECKPOINTS, plot=True, save=True, save_path=SAVE_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "category_orders = {\"checkpoint\": [\"openfibsem-baseline-34\", \"autoliftout-waffle-01-34\"],\n",
    "\"feature\": [\"LamellaCentre\", \"LamellaLeftEdge\", \"LamellaRightEdge\", \"NeedleTip\"]}\n",
    "evaluation._plot_evalution_data(df_eval, thresholds=[250, 100, 50, 25, 10], category_orders=category_orders)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUGMENTED DATASET MODELS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from fibsem.detection import detection\n",
    "from fibsem.segmentation.model import load_model\n",
    "from fibsem.structures import FibsemImage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "from fibsem.structures import Point\n",
    "from fibsem.detection import detection\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "\n",
    "from tqdm import tqdm\n",
    "from fibsem.detection import evaluation\n",
    "\n",
    "\n",
    "# ground truth (user corrections)\n",
    "DATA_PATH = \"/home/patrick/github/data/ML_LOG/data.csv\"\n",
    "\n",
    "# eval checkpoints\n",
    "\n",
    "# BASELINE\n",
    "# CHECKPOINTS = [\n",
    "#     {\"checkpoint\": \"/home/patrick/github/fibsem/fibsem/segmentation/models/model.pt\", \"encoder\": \"resnet18\", \"nc\": 3},\n",
    "#     {\"checkpoint\": \"/home/patrick/github/fibsem/fibsem/segmentation/models/model2.pt\", \"encoder\": \"resnet18\", \"nc\": 3},\n",
    "#     {\"checkpoint\": \"/home/patrick/github/fibsem/fibsem/segmentation/models/model3.pt\", \"encoder\": \"resnet18\", \"nc\": 3},\n",
    "#     {\"checkpoint\": \"openfibsem-baseline-34.pt\", \"encoder\": \"resnet34\", \"nc\": 3},\n",
    "# ]\n",
    "\n",
    "\n",
    "# WAFFLE\n",
    "CHECKPOINTS = [\n",
    "    {\"checkpoint\": \"openfibsem-baseline-34.pt\", \"encoder\": \"resnet34\", \"nc\": 3},\n",
    "    # {\"checkpoint\": \"autoliftout-finetune-34.pt\", \"encoder\": \"resnet34\", \"nc\": 3},\n",
    "    {\"checkpoint\": \"autoliftout-waffle-01-34.pt\", \"encoder\": \"resnet34\", \"nc\": 3},\n",
    "    # {\"checkpoint\": \"/home/patrick/github/fibsem/fibsem/segmentation/models/autoliftout/aug/base/model19.pt\", \"encoder\": \"resnet34\", \"nc\": 3},\n",
    "    # {\"checkpoint\": \"/home/patrick/github/fibsem/fibsem/segmentation/models/autoliftout/aug/base/xl/model29.pt\", \"encoder\": \"resnet50\", \"nc\": 3},\n",
    "    # {\"checkpoint\": \"/home/patrick/github/fibsem/fibsem/segmentation/models/autoliftout/aug/finetune/model29.pt\", \"encoder\": \"resnet34\", \"nc\": 3},\n",
    "    {\"checkpoint\": \"/home/patrick/github/fibsem/fibsem/segmentation/models/autoliftout/aug/base/combo/model19.pt\", \"encoder\": \"resnet50\", \"nc\": 3},\n",
    "    {\"checkpoint\": \"/home/patrick/github/fibsem/fibsem/segmentation/models/autoliftout/aug/base/combo/model24.pt\", \"encoder\": \"resnet50\", \"nc\": 3},\n",
    "    {\"checkpoint\": \"/home/patrick/github/fibsem/fibsem/segmentation/models/autoliftout/aug/base/combo/model29.pt\", \"encoder\": \"resnet50\", \"nc\": 3},\n",
    "\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "TRAIN_PATH = \"/home/patrick/github/data/liftout/train-waffle/train\"\n",
    "filenames = sorted(glob.glob(os.path.join(TRAIN_PATH, \"*.tif\")))\n",
    "print(f\"Found {len(filenames)} images (train)\")\n",
    "\n",
    "# test data\n",
    "TEST_PATH = \"/home/patrick/github/data/liftout/train-waffle/test\"\n",
    "filenames += sorted(glob.glob(os.path.join(TEST_PATH, \"*.tif\")))\n",
    "print(f\"Found {len(filenames)} images (test)\")\n",
    "\n",
    "df_eval = evaluation._run_evaluation(DATA_PATH, filenames, CHECKPOINTS, plot=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_eval)\n",
    "\n",
    "df_eval[\"checkpoint\"] = df_eval[\"checkpoint\"].str.replace(\".pt\", \"\")\n",
    "\n",
    "category_orders = {\"checkpoint\": [\"openfibsem-baseline-34\", \"autoliftout-waffle-01-34\", \"model19\", \"model24\", \"model29\"]}\n",
    "evaluation._plot_evalution_data(df_eval, threshold=25, category_orders=category_orders)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WAFFLE MODEL DATA 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from fibsem.structures import FibsemImage\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "import shutil\n",
    "\n",
    "EXPERIMENTS = [\n",
    "    \"/home/patrick/github/data/EXPERIMENTS/HANNAH-WAFFLE-01-23082023\",\n",
    "    \"/home/patrick/github/data/EXPERIMENTS/HANNAH-WAFFLE-01-22082023\",\n",
    "    \"/home/patrick/github/data/EXPERIMENTS/HANNAH-WAFFLE-O1-170823\",\n",
    "    \"/home/patrick/github/data/EXPERIMENTS/HANNAH-WAFFLE-01-15082023\",    \n",
    "]\n",
    "\n",
    "PATH = \"/home/patrick/github/data/autolamella/train4\"\n",
    "TRAIN_PATH = os.path.join(PATH, \"train\")\n",
    "TEST_PATH = os.path.join(PATH, \"test\")\n",
    "\n",
    "\n",
    "os.makedirs(TRAIN_PATH, exist_ok=True)\n",
    "os.makedirs(TEST_PATH, exist_ok=True)\n",
    "\n",
    "# copy files to train folder\n",
    "\n",
    "filenames = []\n",
    "\n",
    "for EXP_PATH in EXPERIMENTS:\n",
    "    files = glob.glob(os.path.join(EXP_PATH, \"**/ml-*.tif\"), recursive=True)\n",
    "    print(f\"Found {len(files)} images for {os.path.basename(EXP_PATH)}\")\n",
    "    filenames += files\n",
    "\n",
    "shuffle(filenames)\n",
    "SPLIT = 0.5\n",
    "\n",
    "print(f\"Found {len(filenames)} images in total {len(EXPERIMENTS)} experiments\")\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"/home/patrick/github/data/ML_LOG/data.csv\")\n",
    "\n",
    "\n",
    "count = 0\n",
    "for i, fname in enumerate(filenames):\n",
    "\n",
    "    # filter out images that have been corrected\n",
    "    image_fname = os.path.basename(fname)[:-7] \n",
    "    df_filt = df[df[\"image\"] == image_fname]\n",
    "    _is_corrected = df_filt[\"corrected\"].values[0]\n",
    "\n",
    "    # corrected or randomly selected\n",
    "    if _is_corrected or i < int(len(filenames) * SPLIT):\n",
    "        # print(i, f\"{os.path.basename(fname)}\", image_fname, _is_corrected)\n",
    "        # img = FibsemImage.load(fname)\n",
    "        # plt.imshow(img.data, cmap=\"gray\")\n",
    "        # plt.show()\n",
    "        count += 1\n",
    "        # shutil.copy(fname, os.path.join(TRAIN_PATH, f\"{os.path.basename(fname)}\"))\n",
    "    else:\n",
    "        # shutil.copy(fname, os.path.join(TEST_PATH, f\"{os.path.basename(fname)}\"))\n",
    "\n",
    "    # if i > 5:\n",
    "        # break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Found {count} images in total\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoLamella Waffle (TEST SET ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from fibsem.detection import evaluation\n",
    "\n",
    "########## TEST (TEST ONLY)\n",
    "\n",
    "# ground truth (user corrections)\n",
    "DATA_PATH = \"/home/patrick/github/data/ML_LOG/data.csv\"\n",
    "\n",
    "# eval checkpoints\n",
    "CHECKPOINTS = [\n",
    "    {\"checkpoint\": \"openfibsem-baseline-34.pt\", \"encoder\": \"resnet34\", \"nc\": 3},\n",
    "    {\"checkpoint\": \"autolamella-02-34.pt\", \"encoder\": \"resnet34\", \"nc\": 3},\n",
    "    # {\"checkpoint\": \"autolamella-03-34.pt\", \"encoder\": \"resnet34\", \"nc\": 3},\n",
    "    {\"checkpoint\": \"autolamella-04-34.pt\", \"encoder\": \"resnet34\", \"nc\": 3},\n",
    "    {\"checkpoint\": \"/home/patrick/github/fibsem/fibsem/segmentation/models/autolamella/autolamella-05-aug-34.pt\", \n",
    "     \"encoder\": \"resnet34\", \"nc\": 3},\n",
    "]\n",
    "\n",
    "\n",
    "# test data\n",
    "TEST_PATH = \"/home/patrick/github/data/autolamella/test/\"\n",
    "filenames = sorted(glob.glob(os.path.join(TEST_PATH, \"*.tif\")))\n",
    "print(f\"Found {len(filenames)} images (test)\")\n",
    "\n",
    "SAVE_PATH = \"/home/patrick/github/data/liftout/paper/eval/autolamella-waffle/test\"\n",
    "df_eval = evaluation._run_evaluation(DATA_PATH, filenames, CHECKPOINTS, plot=True, _clip=True, save=True, save_path=SAVE_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_orders={\"checkpoint\": [\"openfibsem-baseline-34\", \"autolamella-02-34\", \"autolamella-04-34\",  \"autolamella-05-aug-34\"], \n",
    "                    \"feature\": [\"LamellaCentre\", \"LamellaTopEdge\"]}\n",
    "\n",
    "evaluation._plot_evalution_data(df_eval, thresholds=[250, 100, 50, 25, 10], category_orders=category_orders)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoLamella Waffle (EVAL SET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### EVAL (TRAIN+TEST) ##############\n",
    "\n",
    "# ground truth (user corrections)\n",
    "DATA_PATH = \"/home/patrick/github/data/ML_LOG/data.csv\"\n",
    "\n",
    "# eval checkpoints\n",
    "CHECKPOINTS = [\n",
    "    {\"checkpoint\": \"openfibsem-baseline-34.pt\", \"encoder\": \"resnet34\", \"nc\": 3},\n",
    "    {\"checkpoint\": \"autolamella-02-34.pt\", \"encoder\": \"resnet34\", \"nc\": 3},\n",
    "    {\"checkpoint\": \"autolamella-03-34.pt\", \"encoder\": \"resnet34\", \"nc\": 3},\n",
    "    {\"checkpoint\": \"autolamella-04-34.pt\", \"encoder\": \"resnet34\", \"nc\": 3},\n",
    "    {\"checkpoint\": \"/home/patrick/github/fibsem/fibsem/segmentation/models/autolamella/autolamella-05-aug-34.pt\", \n",
    "     \"encoder\": \"resnet34\", \"nc\": 3},\n",
    "]\n",
    "\n",
    "\n",
    "TRAIN_PATH = \"/home/patrick/github/data/autolamella/train4/train\"\n",
    "filenames = sorted(glob.glob(os.path.join(TRAIN_PATH, \"*.tif\")))\n",
    "print(f\"Found {len(filenames)} images (train)\")\n",
    "\n",
    "# test data\n",
    "TEST_PATH = \"/home/patrick/github/data/autolamella/test/\"\n",
    "filenames +=sorted(glob.glob(os.path.join(TEST_PATH, \"*.tif\")))\n",
    "print(f\"Found {len(filenames)} images (test)\")\n",
    "\n",
    "SAVE_PATH = \"/home/patrick/github/data/liftout/paper/eval/autolamella-waffle/all\"\n",
    "df_eval = evaluation._run_evaluation(DATA_PATH, filenames, CHECKPOINTS, plot=True, _clip=True, save=True, save_path=SAVE_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_orders={\"checkpoint\": [\"openfibsem-baseline-34\", \"autolamella-02-34\", \"autolamella-03-34\", \"autolamella-04-34\",  \"autolamella-05-aug-34\"], \n",
    "                    \"feature\": [\"LamellaCentre\", \"LamellaTopEdge\"]}\n",
    "\n",
    "evaluation._plot_evalution_data(df_eval, thresholds=[250, 100, 50, 25, 10], category_orders=category_orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB: test data is not corrected, all corrected data is used for training, therefore remaining test data was images that prev were correct.\n",
    "# That is why 03 is so close to the ground truth, the test set only includes images that were not corrected (from runs using 03)\n",
    "# I need a third set of data, that is corrected, but not used for training or testing, which would be next deployed run \n",
    "# Segmentation quality is way up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_eval = pd.read_csv(\"/home/patrick/github/data/liftout/paper/eval/autolamella-waffle/all/eval.csv\")\n",
    "category_orders={\"checkpoint\": [\"openfibsem-baseline-34\", \"autolamella-02-34\", \"autolamella-03-34\", \"autolamella-04-34\",  \"autolamella-05-aug-34\"], \n",
    "                    \"feature\": [\"LamellaCentre\", \"LamellaTopEdge\"]}\n",
    "\n",
    "evaluation._plot_evalution_data(df_eval, thresholds=[250, 100, 50, 25, 10], category_orders=category_orders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "df_group = df.groupby([\"fname\", \"feature\", ]).agg({\"distance\": [np.min, np.argmin]}).reset_index()\n",
    "# checkpoints map\n",
    "checkpoints = df[\"checkpoint\"].unique()\n",
    "df_group[\"best-checkpoint\"] = checkpoints[df_group[\"distance\"][\"argmin\"].values]\n",
    "\n",
    "# group by feature, best-checkpoint count\n",
    "df_group = df_group.groupby([\"best-checkpoint\", \"feature\"]).count().reset_index()\n",
    "\n",
    "# flatten columns\n",
    "df_group.columns = df_group.columns.get_level_values(0)\n",
    "\n",
    "# rename columns\n",
    "df_group = df_group.rename(columns={\"fname\": \"count\"})\n",
    "# drop distance column\n",
    "df_group = df_group.drop(columns=[\"distance\"])\n",
    "\n",
    "display(df_group)\n",
    "\n",
    "# plot bar chart\n",
    "fig = px.pie(df_group, values=\"count\", facet_col=\"feature\", names=\"best-checkpoint\", title=\"Best Checkpoint by Feature\")\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('autoliftout')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea78b76b2c840a5577de64ec81812954f7a3177bd4e73b9895b7933ce81940d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
